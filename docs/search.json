[
  {
    "objectID": "anova.html",
    "href": "anova.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "anova.html#anova-com-três-fatores",
    "href": "anova.html#anova-com-três-fatores",
    "title": "",
    "section": "ANOVA com três fatores",
    "text": "ANOVA com três fatores\nAqui vamos usar dados a\n\n\nCode\nlibrary(googlesheets4)\nlibrary(gsheet)\nlibrary(ggplot2)\n\nurl &lt;- \"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1507017964#gid=1507017964\"\n\nmilho &lt;- gsheet2tbl(url)\n\nhead(milho)\n\n\n# A tibble: 6 × 6\n   tipo umidade tempo   rep peso_vol peso_mil\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1     1      13     0     1     704.     291.\n2     1      13     0     2     708.     290.\n3     1      13     0     3     701.     298.\n4     2      13     0     1     704.     291.\n5     2      13     0     2     708.     290.\n6     2      13     0     3     701.     298.\n\n\nCode\nmilho |&gt;\n  filter(tempo ==8) |&gt;\n  ggplot(aes(factor(tipo), peso_mil,\n             color = factor(umidade)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~ umidade)\n\n\n\n\n\nInteração entre tipo de armazenamento e o tempo (8)\n\n\nCode\nmilho2 &lt;- milho |&gt;\n  filter(tempo ==8)\n\nm2 &lt;- aov(peso_mil ~ factor(tipo)*factor(umidade),\n          data = milho2)\nsummary(m2)\n\n\n                             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nfactor(tipo)                  1  11215   11215  2375.8 3.64e-15 ***\nfactor(umidade)               2  42814   21407  4534.8  &lt; 2e-16 ***\nfactor(tipo):factor(umidade)  2   2329    1165   246.7 1.79e-10 ***\nResiduals                    12     57       5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTipo de inoculação na incidencia de Fusarium\n\n\nCode\nmilho3 &lt;- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\nm4 &lt;- aov(yield ~hybrid*method,\n          data = milho3)\nsummary(m4)\n\n\n              Df    Sum Sq  Mean Sq F value   Pr(&gt;F)    \nhybrid         5 105876446 21175289   8.312 2.66e-05 ***\nmethod         1     42951    42951   0.017    0.897    \nhybrid:method  5  10619453  2123891   0.834    0.534    \nResiduals     36  91709593  2547489                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\ncheck_heteroscedasticity(m4)\n\n\nOK: Error variance appears to be homoscedastic (p = 0.928).\n\n\n\n\nCode\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\nCode\nmedias_m4 &lt;- emmeans(m4, ~ hybrid)\nmedias_m4\n\n\n hybrid   emmean  SE df lower.CL upper.CL\n 30F53 HX  10598 564 36     9453    11742\n 30F53 YH   9309 564 36     8165    10454\n 30K64     11018 564 36     9874    12162\n 30S31H     8652 564 36     7507     9796\n 30S31YH    8056 564 36     6912     9201\n BG7049H   12402 564 36    11257    13546\n\nResults are averaged over the levels of: method \nConfidence level used: 0.95 \n\n\n\n\nCode\ncld(medias_m4)\n\n\n hybrid   emmean  SE df lower.CL upper.CL .group\n 30S31YH    8056 564 36     6912     9201  1    \n 30S31H     8652 564 36     7507     9796  12   \n 30F53 YH   9309 564 36     8165    10454  12   \n 30F53 HX  10598 564 36     9453    11742   23  \n 30K64     11018 564 36     9874    12162   23  \n BG7049H   12402 564 36    11257    13546    3  \n\nResults are averaged over the levels of: method \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nSe a interação não der significativa, nos retiramos a interação e deixamos so o fator que teve significancia.\n\n\nCode\nm5 &lt;- aov(yield ~hybrid, data = milho3)\nsummary(m5)\n\n\n            Df    Sum Sq  Mean Sq F value   Pr(&gt;F)    \nhybrid       5 105876446 21175289   8.688 1.02e-05 ***\nResiduals   42 102371996  2437428                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\nm4 &lt;- aov(yield ~hybrid,\n          data = milho3)\nsummary(m5)\n\n\n            Df    Sum Sq  Mean Sq F value   Pr(&gt;F)    \nhybrid       5 105876446 21175289   8.688 1.02e-05 ***\nResiduals   42 102371996  2437428                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nchecando a heteroscedasticidade:\n\n\nCode\ncheck_heteroscedasticity(m5)\n\n\nOK: Error variance appears to be homoscedastic (p = 0.763).\n\n\n\n\nCode\nplot(simulateResiduals(m5))\n\n\n\n\n\n\n\nCode\nmedias_m5 &lt;- emmeans(m5, ~hybrid)\nmedias_m5\n\n\n hybrid   emmean  SE df lower.CL upper.CL\n 30F53 HX  10598 552 42     9484    11712\n 30F53 YH   9309 552 42     8195    10423\n 30K64     11018 552 42     9904    12132\n 30S31H     8652 552 42     7538     9765\n 30S31YH    8056 552 42     6942     9170\n BG7049H   12402 552 42    11288    13516\n\nConfidence level used: 0.95 \n\n\n\n\nCode\ncld(medias_m5)\n\n\n hybrid   emmean  SE df lower.CL upper.CL .group\n 30S31YH    8056 552 42     6942     9170  1    \n 30S31H     8652 552 42     7538     9765  12   \n 30F53 YH   9309 552 42     8195    10423  123  \n 30F53 HX  10598 552 42     9484    11712   234 \n 30K64     11018 552 42     9904    12132    34 \n BG7049H   12402 552 42    11288    13516     4 \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nCode\npwpm(medias_m5)\n\n\n         30F53 HX 30F53 YH   30K64  30S31H 30S31YH BG7049H\n30F53 HX  [10598]   0.5709  0.9942  0.1494  0.0254  0.2125\n30F53 YH     1288  [ 9309]  0.2643  0.9576  0.5999  0.0036\n30K64        -420    -1709 [11018]  0.0447  0.0059  0.4938\n30S31H       1946      658    2366 [ 8652]  0.9723  0.0003\n30S31YH      2541     1253    2962     595 [ 8056]  &lt;.0001\nBG7049H     -1804    -3092   -1384   -3750   -4345 [12402]\n\nRow and column labels: hybrid\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\nDados Não Paramétricos com Dois ou Mais Fatores — Uso de Ranks\nQuando se trabalha com dados não paramétricos envolvendo apenas um fator, é possível aplicar transformações, testes não paramétricos (como Kruskal-Wallis) ou modelos lineares generalizados, conforme discutido anteriormente.\nNo entanto, quando há dois ou mais fatores, especialmente com interação entre eles, os testes não paramétricos convencionais não são adequados. Nesses casos, uma abordagem alternativa é utilizar o método dos postos (rank).\nEsse método consiste em transformar os dados em ranks (valores ordenados), permitindo a aplicação de modelos lineares aos dados ranqueados. Com isso, é possível avaliar os efeitos principais e a interação entre os fatores, mesmo quando os pressupostos da ANOVA não são atendidos.\n\n\nCode\nfung &lt;- read_excel(\"dados-diversos.xlsx\", \"fungicida_vaso\")\nfung2 &lt;- fung |&gt;\n  mutate(inc = inf_seeds/n_seeds*100,\n         rank_inc = rank(inc))\nrank_anova &lt;- aov(rank_inc ~treat*dose, data = fung2)\nsummary(rank_anova)\n\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ntreat        1 192.20  192.20  11.596 0.00362 **\ndose         1  76.05   76.05   4.588 0.04792 * \ntreat:dose   1 120.05  120.05   7.243 0.01606 * \nResiduals   16 265.20   16.58                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nvamos usar emmeans para ver as medias em rank:\n\n\nCode\nmeans_rank &lt;- emmeans(rank_anova, ~treat | dose)\ncld(means_rank)\n\n\ndose = 0.5:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole    6.9 1.82 16     3.04     10.8  1    \n Ionic liquid   18.0 1.82 16    14.14     21.9   2   \n\ndose = 2.0:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole    7.9 1.82 16     4.04     11.8  1    \n Ionic liquid    9.2 1.82 16     5.34     13.1  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAgora podemos criar a tabela e colocar os dados originais com os dados rankeados."
  },
  {
    "objectID": "anova.html#anova-com-bloco-dbc",
    "href": "anova.html#anova-com-bloco-dbc",
    "title": "",
    "section": "Anova com bloco (DBC)",
    "text": "Anova com bloco (DBC)\nVamos usar o conjunto de dados fungicida_campo:\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nfungicidas &lt;- read_excel(\"dados-diversos.xlsx\", \"fungicida_campo\")"
  },
  {
    "objectID": "anova.html#modelo-anova-com-bloco",
    "href": "anova.html#modelo-anova-com-bloco",
    "title": "",
    "section": "Modelo Anova com bloco",
    "text": "Modelo Anova com bloco\nO modelo de ANOVA com blocos é utilizado quando há uma fonte de variação adicional além dos tratamentos, chamada de bloco. O objetivo dos blocos é controlar a variabilidade entre unidades experimentais que poderiam afetar os resultados, tornando a comparação entre tratamentos mais precisa.\nÉ especialmente útil quando as unidades experimentais são heterogêneas, mas podem ser agrupadas em subconjuntos (blocos) relativamente homogêneos.\nNo delineamento em blocos, adiciona o sinal de + para adicionar a repetição.\n\n\nCode\nnames(fungicidas)\n\n\n[1] \"TRAT\"  \"BLOCO\" \"DFC\"   \"FER\"   \"PROD\" \n\n\nCode\naov_fung &lt;- aov(PROD ~ TRAT + BLOCO, data = fungicidas)\nsummary(aov_fung)\n\n\n            Df  Sum Sq Mean Sq F value Pr(&gt;F)  \nTRAT         1 1303140 1303140   7.310 0.0113 *\nBLOCO        1   33403   33403   0.187 0.6683  \nResiduals   29 5169700  178266                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVerificando as premissas:\n\n\nCode\nlibrary(performance)\nlibrary(DHARMa)\ncheck_normality(aov_fung)\n\n\nWarning: Non-normality of residuals detected (p = 0.036).\n\n\n\n\nCode\ncheck_heteroscedasticity(aov_fung)\n\n\nOK: Error variance appears to be homoscedastic (p = 0.338).\n\n\n\n\nCode\nplot(simulateResiduals(aov_fung))\n\n\n\n\n\nAgora vamos estimar as médias:\n\n\nCode\nlibrary(emmeans)\nmeans_fung &lt;- emmeans(aov_fung, ~TRAT)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(means_fung)\n\n\n TRAT emmean   SE df lower.CL upper.CL .group\n  4.5   4999 74.6 29     4846     5151  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nCode\nplot(means_fung)+\n  coord_flip()+\n  theme_minimal()"
  },
  {
    "objectID": "aula2.html",
    "href": "aula2.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "aula2.html#instalação-de-pacotes-e-comandos-básicos",
    "href": "aula2.html#instalação-de-pacotes-e-comandos-básicos",
    "title": "",
    "section": "Instalação de Pacotes e Comandos básicos",
    "text": "Instalação de Pacotes e Comandos básicos\n\nO que são pacotes no R?\nNo R, pacotes são conjuntos organizados de funções, dados e documentação que ampliam as capacidades da linguagem. Eles funcionam como extensões modulares que podem ser instaladas conforme a necessidade, permitindo realizar análises específicas, criar gráficos, importar dados e muito mais. Em outras palavras, um pacote é uma forma prática de acessar códigos já prontos e úteis para diversas tarefas analíticas.\nEsses pacotes são distribuídos em repositórios, sendo os mais utilizados:\n\nCRAN (Comprehensive R Archive Network) – é o repositório oficial e mais utilizado para distribuição de pacotes criados pela comunidade.\nBioconductor – voltado especialmente para aplicações em bioinformática e análise de dados genômicos.\nGitHub – uma plataforma que hospeda projetos de código aberto, incluindo versões em desenvolvimento ou alternativas de pacotes R que ainda não estão disponíveis no CRAN.\n\nA escolha dos pacotes depende do tipo de análise a ser realizada. No entanto, alguns pacotes são amplamente utilizados em diferentes contextos por oferecerem ferramentas fundamentais para manipulação e visualização de dados. Entre os principais, destacam-se:\n\ntidyverse – uma coleção de pacotes que compartilham uma filosofia comum de manipulação de dados;\ndplyr – facilita o trabalho com data frames por meio de verbos como filter(), select() e mutate();\nreadxl – permite importar planilhas do Excel de forma simples;\nggplot2 – pacote poderoso para criação de gráficos personalizados.\n\n\n\nInstalação e Carregamento de Pacotes no R\nPara utilizar recursos adicionais no R, é necessário instalar e carregar pacotes específicos. Pacotes são coleções organizadas de funções, dados e documentação que estendem as funcionalidades básicas do R. Eles podem ser instalados e carregados tanto por meio da interface gráfica do RStudio quanto por comandos no console.\n\nInstalação de pacotes\nA instalação pode ser feita de duas formas:\n\nVia menu gráfico (GUI):\n\nAcesse o menu Tools &gt; Install Packages ou clique na aba Packages &gt; Install.\nDigite o nome do(s) pacote(s) que deseja instalar.\nClique em “Install” e o RStudio irá baixar e instalar automaticamente a partir do repositório CRAN (ou outro repositório, se especificado).\n\nVia comando no console:\nUtilize a função install.packages() passando o nome do pacote entre aspas:\n\n\n\nCode\n#install.packages(\"ggplot2\")\n\n##Instalar múltiplos pacotes\n\n#install.packages(c(\"dplyr\", \"readxl\", \"tidyverse\", \"GWalkR\", \"tidyr\", \"readr\", \"caret\"))\n\n\nAtenção: A instalação de pacotes precisa ser feita apenas uma vez. Porém, sempre que iniciar um novo projeto ou sessão no R, será necessário carregá-los novamente.\n\n\nCarregamento de pacotes\nApós a instalação, é necessário carregar o pacote para utilizá-lo na sessão atual. ndefinedndefinedndefinedIsso pode ser feito de duas formas:\n\nVia menu gráfico:\n\n\nVá até a aba Packages no painel inferior direito do RStudio.\nUse a barra de busca para localizar o pacote desejado.\nMarque a caixa ao lado do nome do pacote para ativá-lo (carregá-lo).\n\n\nVia comando no console:\nÉ possível carregar vários pacotes na mesma célula (chunk) ou bloco de código, separando os comandos em linhas diferentes\nUtilize a função library() com o nome do pacote (sem aspas):\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(metafor) \nlibrary(gsheet) \nlibrary(remotes) \nlibrary(ggplot2) \nlibrary(dplyr)\n\n\n\n\nSilenciar mensagens e avisos\nAlguns pacotes exibem mensagens e avisos (warnings) extensos ao serem carregados, o que pode deixar o script visualmente poluído. Para evitar isso, é comum utilizar argumentos especiais dentro de blocos de código no R Markdown, como:\n\n\nCode\n{warning(FALSE)}\n\n\nEsses parâmetros ocultam mensagens e avisos durante a execução, tornando a saída do código mais limpa e organizada — especialmente útil em relatórios e apresentações geradas via R Markdown ou Quarto.\n\n\n\nDicas importantes\n\nSempre carregue os pacotes no início do script ou notebook. Isso garante que todas as funções estarão disponíveis ao longo da análise.\nVerifique se o nome do pacote está digitado corretamente. O R é case sensitive, ou seja, diferencia letras maiúsculas e minúsculas.\nSe um pacote estiver ausente ou não carregar corretamente, reinstale-o com install.packages()."
  },
  {
    "objectID": "aula2.html#funções-de-pacotes",
    "href": "aula2.html#funções-de-pacotes",
    "title": "",
    "section": "Funções de pacotes",
    "text": "Funções de pacotes\n\nChamando Funções de Pacotes no R\nAs funções contidas em pacotes do R são diversas e poderosas, e serão exploradas com mais profundidade nas próximas aulas — especialmente no tema data frames. Por ora, vamos conhecer rapidamente como utilizar uma dessas funções, com um exemplo prático.\nA função arrange(), pertencente ao pacote dplyr, é utilizada para ordenar os dados com base em uma ou mais variáveis. Vamos aplicá-la ao dataset mtcars, que já vem incluso no R como exemplo de base de dados para testes e aprendizagem.\nNo exemplo abaixo, usamos arrange() para reorganizar o conjunto de dados mtcars com base na variável cyl (número de cilindros), em ordem crescente:\n\n\nCode\n{library(dplyr)}\n\narrange(mtcars, cyl)\n\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n\n\nEsse comando reordena as linhas da tabela mtcars a partir dos menores valores de cyl. Caso fosse necessário ordenar em ordem decrescente, utilizaríamos a função desc() dentro do arrange().\n\n\nGerar relatórios e apresentações em PDF, a partir de um documento RMarkdown\n\n\nCode\n#install.packages('tinytex')\n#tinytex::install_tinytex()  # instalar o TinyTeX"
  },
  {
    "objectID": "boxcox.html",
    "href": "boxcox.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "boxcox.html#transformação-de-dados-r-tipo-boxcox",
    "href": "boxcox.html#transformação-de-dados-r-tipo-boxcox",
    "title": "",
    "section": "Transformação de dados R tipo Boxcox",
    "text": "Transformação de dados R tipo Boxcox\nA transformação Box-Cox é um método amplamente utilizado em estatística para ajustar dados contínuos positivos, facilitando o cumprimento dos pressupostos de normalidade e homogeneidade das variâncias em análises. Essa técnica é especialmente útil quando os dados apresentam assimetria ou variabilidade não constante.\nA transformação é expressa pela fórmula:\ny(λ) = (x^λ- 1) / λ\nonde:\n\nx é o valor original da variável,\ny(λ) é o valor transformado;\nλ é o parâmetro que controla a transformação e pode assumir qualquer valor real.\n\nDependendo do valor de λ, a transformação assume diferentes formas:\n\nSe 0λ=0, a transformação equivale ao logaritmo natural dos dados,\nSe λ=1, os dados permanecem praticamente inalterados (transformação linear),\nPara valores negativos de λ, a transformação é do tipo inversa.\n\nPara realizar essa transformação no R, o pacote MASS oferece funções específicas que facilitam a estimação do parâmetro λ ideal para os dados e a aplicação da transformação.\n\n\nCode\nlibrary(MASS)\nrm(survey)\nhead(MASS::survey)\n\n\n     Sex Wr.Hnd NW.Hnd W.Hnd    Fold Pulse    Clap Exer Smoke Height      M.I\n1 Female   18.5   18.0 Right  R on L    92    Left Some Never 173.00   Metric\n2   Male   19.5   20.5  Left  R on L   104    Left None Regul 177.80 Imperial\n3   Male   18.0   13.3 Right  L on R    87 Neither None Occas     NA     &lt;NA&gt;\n4   Male   18.8   18.9 Right  R on L    NA Neither None Never 160.00   Metric\n5   Male   20.0   20.0 Right Neither    35   Right Some Never 165.00   Metric\n6 Female   18.0   17.7 Right  L on R    64   Right Some Never 172.72 Imperial\n     Age\n1 18.250\n2 17.583\n3 16.917\n4 20.333\n5 23.667\n6 21.000\n\n\nCode\nls()\n\n\n[1] \"has_annotations\"\n\n\n\nInsectSprays do R\nPara a transformação Box-Cox, utilizaremos o conjunto de dados InsectSprays, disponível no R. A função boxcox() do pacote MASS é uma ferramenta que calcula a transformação de Box-Cox e ajuda a determinar o valor ideal do parâmetro lambda para uma variável específica. Além de fornecer o valor ótimo de lambda, essa função gera gráficos de diagnóstico que auxiliam na avaliação da adequação da transformação aos dados, facilitando a interpretação e a decisão sobre qual transformação aplicar.\n\n\nCode\ninsects &lt;- InsectSprays\n\nb &lt;- boxcox(lm(insects$count+0.1 ~1))\n\n\n\n\n\nCódigo para mostrar o valor de lambda, que maximiza a função log-verossimilhança, sendo esse o parâmetro ideal para a transformação Box-Cox dos dados.\n\n\nCode\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n\n[1] 0.4242424\n\n\nHistograma para visualização dos dados\n\n\nCode\ninsects$count2 &lt;- (insects$count ^ lambda - 1) / lambda\n\nhist(insects$count, col = \"salmon\", main = \"Histograma de insects$count\", xlab = \"count\")\n\n\n\n\n\n\n\nCode\nhist(insects$count2, col = \"pink\", main = \"Histograma de insects$count2 (transformada)\", xlab = \"count2\")\n\n\n\n\n\n\n\nCode\ninsects$count2\n\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760"
  },
  {
    "objectID": "correlacao.html",
    "href": "correlacao.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "correlacao.html#análise-de-correlação",
    "href": "correlacao.html#análise-de-correlação",
    "title": "",
    "section": "Análise de Correlação",
    "text": "Análise de Correlação\nA análise de correlação é uma técnica estatística utilizada para quantificar a força e a direção da relação linear entre duas variáveis contínuas. Ela indica o grau em que essas variáveis variam em conjunto.\nA correlação pode ser:\n\nPositiva: ambas as variáveis aumentam ou diminuem juntas\nNegativa: uma variável aumenta enquanto a outra diminui;\nNula: não há relação linear aparente entre elas.\n\nO principal indicador usado é o coeficiente de correlação de Pearson, que varia entre -1 e +1:\n\n+1: correlação linear positiva perfeita;\n-1: correlação linear negativa perfeita;\n0: ausência de correlação linear.\n\nÉ importante ressaltar que a correlação não implica causalidade, ou seja, mesmo quando duas variáveis estão correlacionadas, isso não significa que uma causa a outra.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\n\nestande = read_xlsx(\"dados-diversos.xlsx\", sheet = \"estande\")\n\nestande |&gt;\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  facet_wrap(~ exp)+\n  ylim(0,max(estande$nplants))+\n  geom_smooth(se =  F)\n\n\n\n\n\n\nAjuste de Modelo Linear Simples e Quadrático\nPara ajustar modelos lineares em R, utiliza-se a função lm(), que recebe como argumentos a fórmula da relação entre a variável dependente e a independente (por exemplo, y ~ x) e o conjunto de dados. O modelo ajustado é armazenado como um objeto do tipo \"lm\". Para visualizar os resultados do ajuste, utiliza-se a função summary(), que retorna os coeficientes estimados, valores-p, o coeficiente de determinação (R²), e outros diagnósticos importantes.\n\n\nCoeficiente de Determinação (R²)\nO R² indica a proporção da variação da variável resposta explicada pelo modelo. Seu valor varia entre 0 e 1:\n\nR² = 0: o modelo não explica nenhuma variação;\nR² = 1: o modelo explica totalmente a variação da variável dependente.\n\nValores mais altos de R² indicam melhor ajuste aos dados.\n\n\nComparando modelos: linear vs. quadrático\nÉ possível comparar um modelo linear simples (y ~ x) com um modelo quadrático (y ~ x + I(x^2)) para verificar qual se ajusta melhor aos dados. O critério pode ser baseado no R², AIC ou inspeção gráfica dos resíduos.\n\n\nCode\nestande2 &lt;- estande |&gt;\n  filter(exp ==2) |&gt;\n  group_by(trat) |&gt;\n  summarise(mean_nplants = mean(nplants))\n  \nestande2|&gt;\n  ggplot(aes(trat, mean_nplants))+\n  geom_point()+\n  #geom_line()\n  geom_smooth(formula = y ~ poly(x, 2), method = \"lm\", color = \"blue\")+\n  annotate(geom = \"text\", \n           x = 25, y = 70,\n           label = \"y = 66.3 - 1.777x + 0.0222x2\n           R2 = 0.0.88\")\n\n\n\n\n\n\n\nModelo Quadrático\nEnquanto a correlação linear avalia a relação entre duas variáveis com base em uma linha reta, o modelo quadrático permite identificar padrões não lineares, especialmente aqueles que descrevem uma curva (por exemplo, em forma de U ou inverso de U).\nPara ajustar um modelo quadrático no R, utiliza-se a função lm(), assim como no modelo linear simples. A diferença está na fórmula: é necessário incluir o termo quadrático da variável independente.\n\n\nCode\nestande2 &lt;- estande2 |&gt;\n  mutate(trat2 = trat^2)\n  m1 &lt;- lm(mean_nplants ~ trat, data = estande2)\nsummary(m1)\n\n\n\nCall:\nlm(formula = mean_nplants ~ trat, data = estande2)\n\nResiduals:\n     1      2      3      4      5      6 \n12.764 -2.134 -6.782 -3.327 -4.669  4.147 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     4.5505  13.402 0.000179 ***\ntrat         -0.7007     0.2012  -3.483 0.025294 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.117 on 4 degrees of freedom\nMultiple R-squared:  0.752, Adjusted R-squared:   0.69 \nF-statistic: 12.13 on 1 and 4 DF,  p-value: 0.02529\n\n\n\n\nCode\nhist(m1$residuals, \n     main = \"Histograma dos Resíduos\", \n     xlab = \"Resíduos\", \n     col = \"pink\",      \n     border = \"white\")  \n\n\n\n\n\n\n\nCode\nm2 &lt;- lm(mean_nplants ~ trat + trat2,\n         data = estande2)\nsummary(m2)\n\n\n\nCall:\nlm(formula = mean_nplants ~ trat + trat2, data = estande2)\n\nResiduals:\n      1       2       3       4       5       6 \n 7.4484 -4.4200 -6.4386  1.0739  3.0474 -0.7111 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.70800  14.083 0.000776 ***\ntrat        -1.77720    0.62263  -2.854 0.064878 .  \ntrat2        0.02223    0.01242   1.790 0.171344    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.517 on 3 degrees of freedom\nMultiple R-squared:  0.8801,    Adjusted R-squared:  0.8001 \nF-statistic: 11.01 on 2 and 3 DF,  p-value: 0.04152\n\n\n\n\nCode\nAIC(m1, m2)\n\n\n   df      AIC\nm1  3 45.72200\nm2  4 43.36151\n\n\n\n\nDuas variáveis resposta\nQuando se trabalha com duas variáveis resposta contínuas, é comum investigar a relação entre elas por meio da análise de correlação. O coeficiente de correlação de Pearson (R) é utilizado para quantificar essa relação linear.\nO valor de R varia entre -1 e 1, indicando a direção e a intensidade da associação:\n\nValores próximos de +1 indicam forte correlação positiva,\nValores próximos de -1 indicam forte correlação negativa,\nValores próximos de zero indicam pouca ou nenhuma correlação linear.\n\nO coeficiente de determinação, R², corresponde ao quadrado de R, e representa a proporção da variância de uma variável que é explicada pela outra em uma relação linear. Como R² é o quadrado de R, seu valor será sempre positivo e menor ou igual a 1. Portanto, para valores positivos de R, R² será menor ou igual a R.\n\n\nCode\nlibrary(gsheet)\nmofo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=413008764#gid=413008764\")\n\nhead(mofo)\n\n\n# A tibble: 6 × 5\n  study treat   inc   scl   yld\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1    76  2194  2265\n2     1     2    53  1663  2618\n3     1     3    42  1313  2554\n4     1     4    37  1177  2632\n5     1     5    29   753  2820\n6     1     6    42  1343  2799\n\n\nCode\nmofo |&gt;\n  ggplot(aes(inc, yld))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")+\n  facet_wrap(~ study)\n\n\n\n\n\nO coeficiente de correlação de Pearson é específico para medir relações lineares entre duas variáveis contínuas. Isso significa que ele avalia apenas o grau de associação linear; se a relação entre as variáveis for não linear, o coeficiente de Pearson pode não representar adequadamente a força ou a direção da associação.\n\n\nFunção cor.test()\nNo R, a função cor.test() é utilizada para calcular o coeficiente de correlação entre duas variáveis. Além de estimar o valor da correlação, essa função realiza um teste de hipótese para verificar se a correlação observada é estatisticamente significativa, fornecendo o valor-p e o intervalo de confiança.\nFiltrando o experimento 1:\n\n\nCode\nmofo1 &lt;- mofo |&gt;\n  filter(study ==1)\nmofo1\n\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1     1    76  2194  2265\n 2     1     2    53  1663  2618\n 3     1     3    42  1313  2554\n 4     1     4    37  1177  2632\n 5     1     5    29   753  2820\n 6     1     6    42  1343  2799\n 7     1     7    55  1519  2503\n 8     1     8    40   516  2967\n 9     1     9    26   643  2965\n10     1    10    18   400  3088\n11     1    11    27   643  3044\n12     1    12    28   921  2925\n13     1    13    36  1196  2867\n\n\n\n\nCode\ncor.test(mofo1$inc, mofo1$yld)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -6.8451, df = 11, p-value = 2.782e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9699609 -0.6921361\nsample estimates:\n       cor \n-0.8999278 \n\n\nFiltrando o experimento 2:\n\n\nCode\nmofo1 &lt;- mofo |&gt;\n  filter(study ==2)\nmofo1\n\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     2     1    76  1331  2257\n 2     2     2    44   756  2393\n 3     2     3    24   338  2401\n 4     2     4    33   581  2568\n 5     2     5    37   588  2320\n 6     2     6    34   231  2308\n 7     2     7    31   925  2389\n 8     2     8    16   119  2614\n 9     2     9    10   394  2681\n10     2    10     8   206  2694\n11     2    11    15   275  2674\n12     2    12     7   131  2666\n13     2    13    19   588  2454\n\n\n\n\nCode\ncor.test(mofo1$inc, mofo1$yld)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -4.6638, df = 11, p-value = 0.0006894\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9426562 -0.4790750\nsample estimates:\n       cor \n-0.8149448 \n\n\nFiltrando o experimento 3:\n\n\nCode\nmofo1 &lt;- mofo |&gt;\n  filter(study ==3)\nmofo1\n\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n\n\n\n\nCode\ncor.test(mofo1$inc, mofo1$yld)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -10.9, df = 11, p-value = 3.105e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9872663 -0.8579544\nsample estimates:\n      cor \n-0.956692 \n\n\nFiltrando o experimento 4:\n\n\nCode\nmofo1 &lt;- mofo |&gt;\n  filter(study ==4)\nmofo1\n\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     4     1    69  6216  1893\n 2     4     2    39  2888  2451\n 3     4     3    41  2272  2232\n 4     4     4    39  2868  2609\n 5     4     5    40  2412  2383\n 6     4     6    40  2372  2480\n 7     4     7    44  3424  2577\n 8     4     8    43  1744  2367\n 9     4     9    26  1456  2769\n10     4    10    29  1732  2907\n11     4    11    30  1080  2298\n12     4    12    34  1592  2976\n13     4    13    44  3268  2200\n\n\n\n\nCode\ncor.test(mofo1$inc, mofo1$yld)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -3.7242, df = 11, p-value = 0.003357\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9194503 -0.3327077\nsample estimates:\n       cor \n-0.7467931 \n\n\nVamos fazer uma matriz de correlação, que nada mais é que uma tabela que resume as relações entre pares de variáveis em um conjunto de dados, exibindo os coeficientes de correlação, geralmente de Pearson, para cada combinação possível. Essa ferramenta é essencial para identificar padrões de associação, intensidade e direção entre múltiplas variáveis simultaneamente.\nA matriz ajuda a compreender rapidamente como as variáveis estão relacionadas, permitindo detectar correlações positivas, negativas ou ausência de associação, e é amplamente utilizada em análises exploratórias e prévias a modelos estatísticos mais complexos.\n\n\nCode\nmofo1 &lt;- mofo |&gt;\n  filter(study ==3)\nmofo1\n\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n\n\n\n\nCode\ncor.test(mofo1$inc, mofo1$yld)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -10.9, df = 11, p-value = 3.105e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9872663 -0.8579544\nsample estimates:\n      cor \n-0.956692 \n\n\n\n\nCode\nlibrary(dplyr)\ncor(dplyr::select(mofo1, 3:5))\n\n\n           inc        scl       yld\ninc  1.0000000  0.8441514 -0.956692\nscl  0.8441514  1.0000000 -0.836512\nyld -0.9566920 -0.8365120  1.000000\n\n\n\nGráficos de correlação\nO pacote corrplot é amplamente utilizado para a visualização e análise de matrizes de correlação, oferecendo ferramentas gráficas que facilitam a interpretação das relações entre variáveis em conjuntos de dados.\n\n\nFuncionalidades principais:\n\ncorr.test():\nRealiza testes estatísticos sobre a matriz de correlação, calculando coeficientes, valores-p e intervalos de confiança. Essa função ajuda a avaliar a significância das correlações observadas.\ncorrplot():\nGera diferentes tipos de gráficos para representar visualmente a matriz de correlação. A função permite escolher entre múltiplos estilos e opções de personalização, tornando a análise mais intuitiva.\nOpções de visualização no corrplot():\nMétodos (method) — tipos de gráficos disponíveis:\n\n\"circle\" (círculos)\n\"square\" (quadrados)\n\"ellipse\" (elipses)\n\"number\" (exibe os valores numéricos dos coeficientes)\n\"shade\" (sombras)\n\"color\" (cores preenchidas)\n\"pie\" (gráfico de pizza)\n\n\nA intensidade da cor ou tamanho dos símbolos é proporcional ao valor dos coeficientes de correlação, facilitando a identificação visual da força da associação.\n\nTipos de layout (type):\n\n\"full\" (matriz completa)\n\"upper\" (metade superior da matriz)\n\"lower\" (metade inferior da matriz)\n\n\n\nCode\nmofo1 &lt;- mofo |&gt;\n  filter(study ==3)\nmofo1\n\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n\n\n\n\n\nCode\ncor.test(mofo1$inc, mofo1$yld)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -10.9, df = 11, p-value = 3.105e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9872663 -0.8579544\nsample estimates:\n      cor \n-0.956692 \n\n\n\n\nCode\npcor &lt;- mofo1 |&gt; dplyr::select(3:5) |&gt; cor()\n\nlibrary(corrplot)\ncorrplot(pcor, method = 'number', type = \"lower\")\n\n\n\n\n\n\n\n\nModelo de Kendall\nO coeficiente de correlação de Kendall é uma medida não paramétrica que avalia a associação entre duas variáveis ordinais ou contínuas que podem ser ordenadas. Diferentemente do coeficiente de Pearson, que avalia relações lineares e assume distribuição normal, o método de Kendall é mais robusto para lidar com dados não lineares ou quando a normalidade não é atendida.\nO coeficiente de Kendall varia entre -1 e 1, com interpretações similares às do coeficiente de Pearson:\n\nValores próximos de +1 indicam forte associação positiva;\nValores próximos de -1 indicam forte associação negativa;\nValores próximos de zero indicam pouca ou nenhuma associação.\n\nDevido à sua natureza baseada em pares ordenados, o coeficiente de Kendall é especialmente útil para dados com escalas ordinais ou quando há presença de outliers.\n\n\nCode\nmofo1 &lt;- mofo |&gt;\n  filter(study ==3)\nmofo1\n\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n\n\n\n\nCode\nshapiro.test(mofo1$inc)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  mofo1$inc\nW = 0.87111, p-value = 0.05412\n\n\n\n\nCode\nshapiro.test(mofo1$yld)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  mofo1$yld\nW = 0.92193, p-value = 0.2663\n\n\n\n\nCode\ncor.test(mofo1$inc, mofo1$yld, method = \"spearman\")\n\n\n\n    Spearman's rank correlation rho\n\ndata:  mofo1$inc and mofo1$yld\nS = 715.97, p-value = 7.166e-08\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.9669458 \n\n\n\n\nCode\nlibrary(dplyr)\npcor &lt;- mofo1 |&gt; dplyr::select(3:5) |&gt; cor(method = \"spearman\")\n\n\n#library(corrplot)\n#corrplot(pcor, method = 'number', type = \"lower\")"
  },
  {
    "objectID": "dataframe.html",
    "href": "dataframe.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source\n\n\n\n\nData frame\nNo R, os conjuntos de dados são geralmente armazenados em data frames, que são estruturas organizadas em linhas e colunas, semelhantes a tabelas. Para importar dados, é necessário que o arquivo esteja salvo em um formato compatível, como .csv, .xlsx ou .txt, permitindo que o R leia e organize as informações corretamente para análise.\n\nTipos de data frames e as funções de pacotes\nComo discutido anteriormente no tópico sobre pacotes no R, alguns pacotes são fundamentais para realizar análises de dados, especialmente quando se trabalha com data frames.\nPara carregar um data frame, é possível utilizar pacotes nativos do R, como o datasets, que já vem com diversos conjuntos de dados prontos para uso. Um exemplo é o data frame cars, que pode ser acessado diretamente após o carregamento do pacote.\n\n\nCode\ncars\n\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\n\n\n\nCode\ncars2 &lt;- cars\nspeed &lt;- cars2$speed\nspeed\n\n\n [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14 14 14 15 15\n[26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24 24 24 24 25\n\n\nPara utilizar um data frame disponível em um pacote, é necessário carregar o pacote com a função library() e, em seguida, atribuir o conjunto de dados a um objeto utilizando o operador &lt;-.\nPor exemplo, ao buscar e carregar o pacote r4pde, é possível acessar o painel de ajuda desse pacote para visualizar os data frames incorporados, como o RustSoybean. Para utilizar esse conjunto de dados em sua análise, basta realizar a atribuição:\n\n\nCode\nif (!requireNamespace(\"pak\", quietly = TRUE)) \n  install.packages(\"pak\")\npak::pkg_install(\"emdelponte/r4pde\")\nlibrary(r4pde)\ndf &lt;- RustSoybean\ndf\n\n\n# A tibble: 34 × 7\n   epidemia latitude longitude local              planting   detection  severity\n      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;              &lt;date&gt;     &lt;date&gt;        &lt;dbl&gt;\n 1       23    -23.0     -50.1 Cambara            2003-11-25 2004-02-02     24  \n 2       24    -24.0     -52.4 Campo Mourao       2003-11-28 2004-02-02     21  \n 3       31    -15.5     -55.2 Campo Verde        2004-11-20 2005-01-25     78  \n 4        3    -13.3     -44.6 Correntina         2002-11-10 2003-01-03     85  \n 5       15    -13.3     -44.6 Correntina         2003-11-28 2004-01-31     25  \n 6       34    -25.4     -51.5 Guarapuava         2004-11-29 2005-03-14     32  \n 7        7    -29.2     -53.7 Julio Castilhos    2002-12-15 2003-04-10     40  \n 8       13    -12.1     -45.8 Luis Eduardo Maga… 2003-11-12 2004-02-15     39.2\n 9       33    -12.1     -45.8 Luis Eduardo Maga… 2004-11-19 2005-01-25     55  \n10        1    -23.3     -51.2 Londrina           2002-11-06 2003-02-03     45  \n# ℹ 24 more rows\n\n\nA função básica para leitura de dados no R é a read.table(), que permite importar arquivos estruturados em formato de tabela. O R também oferece diversas variações dessa função, adaptadas a diferentes formatos de arquivos. Entre as mais utilizadas estão read.csv() e read.csv2(), ideais para arquivos .csv com diferentes convenções de separadores. Para leitura de arquivos Excel (.xlsx), pode-se utilizar funções do pacote readxl.\nO tidyverse é uma coleção de pacotes integrados voltados à ciência de dados. Ele reúne ferramentas essenciais como dplyr (manipulação de dados), tidyr (organização de dados), readr (importação de dados), ggplot2 (visualização), entre outros, proporcionando um fluxo de trabalho eficiente, coerente e moderno dentro do R."
  },
  {
    "objectID": "ggplot2.html",
    "href": "ggplot2.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "ggplot2.html#gráfico-de-colunas",
    "href": "ggplot2.html#gráfico-de-colunas",
    "title": "",
    "section": "Gráfico de Colunas",
    "text": "Gráfico de Colunas\nGráficos de colunas são amplamente utilizados para visualizar dados categóricos ou discretos, ou seja, dados que podem ser organizados em grupos ou classes distintas. Esse tipo de gráfico é útil para destacar padrões, comparações e variações entre categorias, facilitando a interpretação visual de distribuições.\nPara gerar um gráfico de colunas no ggplot2, utiliza-se a função geom_col(), que constrói as barras com base nos valores fornecidos. Neste caso, será utilizado o conjunto de dados survey como exemplo. Se for necessário inverter a orientação das barras — tornando-as horizontais — basta aplicar a função coord_flip(), que troca os eixos X e Y, oferecendo uma alternativa visual mais adequada em alguns contextos.\n\n\nCode\n# Carrega os pacotes necessários\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# URL da planilha\nurl &lt;- \"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1118819738#gid=1118819738\"\n\n# Importa os dados da aba \"survey\" da planilha\ndados_survey &lt;- gsheet2tbl(url, sheet = \"survey\")\n\n# Verifica as primeiras linhas para conferência\nhead(dados_survey)\n\n\n# A tibble: 6 × 6\n   year state residue   inc inc_class species\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  \n1  2011 RS    soybean     1 low       Fgra   \n2  2011 RS    soybean     1 low       Fgra   \n3  2011 RS    soybean     1 low       Fgra   \n4  2011 RS    soybean     1 low       Fgra   \n5  2011 RS    soybean     1 low       Fgra   \n6  2011 RS    soybean     1 low       Fgra   \n\n\nCode\n# Filtra os dados do estado RS e conta ocorrências por espécie\ndados_survey |&gt;\n  filter(state == \"RS\") |&gt;\n  count(species) |&gt;\n  ggplot(aes(x = species, y = n)) +\n  geom_col(width = 0.4, fill = \"yellow\") +\n  coord_flip() +\n  labs(\n    x = \"Species\",\n    y = \"Number of Isolates\",\n    title = \"Horizontal Bar Plot\",\n    subtitle = \"Filtered by state: RS\"\n  ) +\n  theme_bw()\n\n\n\n\n\n\n\nCode\n  ggsave(\"Figs/barplot.png\", bg = \"white\")\n\n\n\nFunção facet_wrap\nA função facet_wrap() do pacote ggplot2 é usada para criar múltiplos painéis (subgráficos) de um gráfico, organizando-os em uma grade, a partir de uma variável categórica.\n\n\nCode\ndados_survey |&gt; \n  filter(state == \"RS\") |&gt;\n  count(species, residue) |&gt;\n  ggplot(aes(species, n))+\n  geom_col(width = 0.4,\n           fill = \"yellow\")+\n  coord_flip()+\n  facet_wrap(~residue, ncol = 1)+\n  labs(x = \" \", y = \"Number of isolates\",\n       tiltle = \"Horizontal bar plot\",\n       subtitle = \"Facet\")+\n  theme_bw()\n\n\n\n\n\nsalvando:\n\n\nCode\n  ggsave(\"Figs/barplotfacet.png\", bg = \"white\")"
  },
  {
    "objectID": "graficosdisp.html",
    "href": "graficosdisp.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "graficosdisp.html#gráficos-de-dispersão-histograma-e-gráfico-de-densidade",
    "href": "graficosdisp.html#gráficos-de-dispersão-histograma-e-gráfico-de-densidade",
    "title": "",
    "section": "Gráficos de Dispersão, Histograma e Gráfico de Densidade",
    "text": "Gráficos de Dispersão, Histograma e Gráfico de Densidade\nVamos aprender a criação de graficos de Dispersão, Histograma e Gráfico de Densidade, para isso vamos entender o que cada um representa?\nGráficos de Dispersão são usados para mostrar a relação entre duas variáveis contínuas, ajudando a identificar padrões, tendências ou correlações. São úteis para visualizar se as variáveis têm associação linear ou não.\nHistogramas exibem a distribuição de uma única variável contínua, agrupando os dados em intervalos (bins). Eles ajudam a entender a frequência de valores em cada intervalo, revelando a forma geral da distribuição, como simetria, assimetria e presença de outliers.\nGráficos de Densidade fornecem uma versão suavizada do histograma, mostrando a distribuição de probabilidade da variável contínua. Eles facilitam a comparação entre distribuições e ajudam a identificar tendências e picos na densidade dos dados.\nJuntos, esses gráficos são ferramentas essenciais para a análise exploratória, permitindo compreender a estrutura e o comportamento dos dados antes de aplicar modelos estatísticos. Vamos lá?\n\nGráficos de Dispersão (Scatterplots)\nGráficos de dispersão são utilizados para representar a relação entre duas variáveis numéricas contínuas. Cada ponto no gráfico representa uma observação, posicionada conforme os valores das variáveis nos eixos X (horizontal) e Y (vertical). São úteis para identificar padrões, tendências ou correlações entre variáveis como tempo e velocidade, temperatura e umidade, comprimento e largura, entre outras.\nCom o pacote ggplot2, utilizamos a função geom_point() para construir scatterplots. Esta função permite definir diversas estéticas:\n\nalpha: controla a transparência dos pontos, útil para reduzir sobreposição;\ncolour: define a cor dos pontos com o argumento color = \"nome da cor\";\nfill: define o preenchimento da forma, também com o nome da cor entre aspas;\nshape: altera o formato dos pontos (como círculos, quadrados ou triângulos), permitindo diferenciar categorias;\nsize: controla o tamanho dos pontos, com um valor numérico.\n\n\n\nImportação de dados\nPara importar uma aba específica de um arquivo Excel, usa-se a função read_excel() do pacote readxl. É necessário informar o caminho do arquivo (entre aspas) e, após a vírgula, o nome ou o número da aba. O nome do data frame atribuído geralmente corresponde ao nome da aba para facilitar a organização.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nfungicida_campo &lt;- read_excel(\"dados-diversos.xlsx\", \n                              \"fungicida_campo\")\n\n\nVisualização: Depois, plota-se os dados definindo-se o eixo x e depois o eixo y. Usa-se o stat_summary para plotar a média de forma simples.\n\n\nCode\n#names(fungicida_campo) # para verificar os nomes das colunas do seu dataframe\nfungicida_campo |&gt;\n  ggplot(aes(x = TRAT, y = PROD)) +\n  geom_jitter(width = 0.1, color = \"gray60\") +\n  stat_summary(fun = mean, geom = \"point\", color = \"blue\", size = 3)\n\n\n\n\n\n\n\nCode\n#install.packages(\"Hmisc\") #pacote Hmisc (que define mean_se)\n#library(Hmisc) ## para mean_se\nfungicida_campo |&gt;\nggplot(aes(x = TRAT, y = PROD)) +\n  geom_jitter(width = 0.1, color = \"gray60\") +\n  \n  stat_summary(fun.data = mean_se, color = \"blue\")\n\n\n\n\n\nAlterando o eixo x, presente no banco de dados fungicida_campo, é possível representar os dados em função da produtividade. Ao incluir o argumento alpha dentro da função geom_point(), os pontos no gráfico se tornam mais transparentes, facilitando a visualização em casos de sobreposição.\n\n\nCode\nlibrary(ggthemes)\nfungicida_campo$TRAT &lt;- as.factor(fungicida_campo$TRAT)  # garantir que TRAT seja fator\n\nfungicida_campo |&gt;\n  ggplot(aes(x = TRAT, y = PROD, color = TRAT)) +\n  geom_point(size = 3) +\n  scale_color_colorblind() +\n  theme_minimal()\n\n\n\n\n\nPara adicionar uma linha de tendência aos dados, utiliza-se a função geom_smooth(). O argumento method = \"lm\" ajusta uma regressão linear, enquanto se = FALSE remove a faixa de confiança. O parâmetro linetype permite definir o estilo da linha.\n\n\nCode\nfungicida_campo |&gt;\n  ggplot(aes(x = TRAT, y = PROD)) +\n  geom_point(size = 3, color = \"steelblue\") +\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              color = \"black\",\n              linetype = \"solid\",\n              size = 2) +\n  theme_minimal() +\n  labs(title = \"Relação entre Tratamentpo e Produtividade\",\n       x = \"Tratamento\",\n       y = \"Produtividade\")"
  },
  {
    "objectID": "graficosdisp.html#gráficos-de-dispersão-para-análise-fatorial",
    "href": "graficosdisp.html#gráficos-de-dispersão-para-análise-fatorial",
    "title": "",
    "section": "Gráficos de dispersão para análise fatorial",
    "text": "Gráficos de dispersão para análise fatorial\nVamos trabalhar com outro subconjunto de dados: Milho. Nele iremos avaliar a variaçção da produtividade em função dos métodos de inoculação.\n\n\nCode\nmilho &lt;- read_excel(\"dados-diversos.xlsx\", \"milho\")\nmilho |&gt;\n  ggplot(aes(hybrid, yield, color = method))+\n   scale_color_brewer(palette = \"Dark2\")+\n  geom_jitter(size = 2)+\n  facet_wrap(~hybrid)\n\n\n\n\n\nPara avaliar qual hibrido apresenta mais doença, usamos:\n\n\nCode\nmilho |&gt;\n  ggplot(aes(method, index, color = method))+\n  scale_color_brewer(palette = \"Dark2\")+\n  geom_jitter(size = 2)+\n  facet_wrap(~hybrid)"
  },
  {
    "objectID": "graficosdisp.html#histogramas",
    "href": "graficosdisp.html#histogramas",
    "title": "",
    "section": "Histogramas",
    "text": "Histogramas\n\nConstrução de Histogramas com geom_histogram()\nPara construir histogramas no ggplot2, utilizamos a função geom_histogram(), que exige apenas o mapeamento da variável no eixo x. O eixo y (frequência) é calculado automaticamente com base na contagem dos dados em cada intervalo (bin).\nHistogramas são indicados para avaliar a distribuição de variáveis contínuas, como produtividade, altura, idade, tempo, entre outros. Eles permitem observar características importantes da distribuição dos dados, como:\n\nTendência central (valores mais frequentes),\nVariabilidade (dispersão),\nAssimetria (simetria ou cauda em um dos lados).\n\n\nEstéticas (aesthetics) comuns em geom_histogram():\n\nbins: define o número de barras (ou classes) do histograma.\ncolor: define a cor do contorno das barras.\nfill: define a cor de preenchimento das barras.\n\n\n\n\nExemplo: Histograma da produtividade\nA seguir, construiremos um histograma com base em uma variável contínua — produtividade (yld). Neste gráfico, os valores são agrupados em classes (bins), permitindo observar o padrão de distribuição dos dados.\nPergunta para reflexão:\n\nO histograma mostra uma distribuição simétrica? Assimétrica? Os dados estão concentrados em uma faixa específica?\n\n\n\nCode\np_yield &lt;- milho |&gt;\n  ggplot(aes(x = yield))+\n  geom_histogram(bins = 10, color = \"black\", fill = \"blue\")\n#Mudando de yield para index:\np_index &lt;- milho |&gt;\n  ggplot(aes(x = index))+\n  geom_histogram(bins = 10, color = \"black\", fill = \"orange\")\n#Combinando gráficos com patchowork: deve-se primeiro definir um nome para cada gráfico\n\nlibrary(patchwork)\n(p_yield + p_index)+\nplot_annotation(tag_levels = \"A\")\n\n\n\n\n\n\n\nCode\nggsave(\"figs/histograms.png\", bg = \"white\")"
  },
  {
    "objectID": "graficosdisp.html#gráfico-de-densidade",
    "href": "graficosdisp.html#gráfico-de-densidade",
    "title": "",
    "section": "Gráfico de Densidade",
    "text": "Gráfico de Densidade\nGráficos de densidade são ferramentas poderosas para visualizar a distribuição de probabilidade de uma variável contínua. Eles ajudam a identificar padrões, tendências e assimetrias nos dados, fornecendo uma estimativa suave da densidade de frequência ao longo do intervalo da variável.\nEsses gráficos são especialmente úteis para representar distribuições como:\n\nAlturas ou pesos em uma população,\nPontuações em testes padronizados,\nQualquer outra variável contínua que exija análise da forma de sua distribuição.\n\nNo ggplot2, o gráfico de densidade é criado com a função geom_density(), que calcula e plota uma curva contínua que representa a densidade dos dados, vamos ver como?\n\n\nCode\nmilho |&gt;\n  ggplot(aes(x = index))+\n  geom_density()"
  },
  {
    "objectID": "graficosdisp.html#gráfico-de-colunas",
    "href": "graficosdisp.html#gráfico-de-colunas",
    "title": "",
    "section": "Gráfico de colunas",
    "text": "Gráfico de colunas\nPara aprendermos a criar um gráfico de colunas, iremos usar um subconjunto de dados.\n\n\nCode\ninsect &lt;- read_excel(\"dados-diversos.xlsx\", \"mortalidade\")\ninsect |&gt;\n  pivot_longer(2:3,\n               names_to = \"status\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(inseticida, value, fill = status))+\n  geom_col()"
  },
  {
    "objectID": "hipotese.html",
    "href": "hipotese.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "hipotese.html#o-que-é-o-teste-de-hipoteses-e-como-é-definida",
    "href": "hipotese.html#o-que-é-o-teste-de-hipoteses-e-como-é-definida",
    "title": "",
    "section": "O que é o teste de Hipoteses e como é definida?",
    "text": "O que é o teste de Hipoteses e como é definida?\n\nTeste de Hipóteses\nO teste de hipóteses é um procedimento estatístico utilizado para avaliar se os dados de uma amostra são consistentes com uma suposição formulada sobre a população de origem. Esse processo envolve a comparação entre duas hipóteses:\n\nHipótese nula (H₀): representa a suposição inicial ou padrão sobre a população — por exemplo, de que não há diferença entre grupos ou de que uma média populacional é igual a um valor específico.\nHipótese alternativa (H₁ ou Ha): propõe uma ideia contrária à hipótese nula, indicando que há uma diferença ou efeito significativo.\n\nO objetivo principal é verificar se os dados da amostra fornecem evidências suficientes para rejeitar H₀ em favor de H₁, com base em um nível de significância previamente definido (geralmente 5%).\n\n\nExemplo de Formulação de Hipóteses\nSe quisermos testar se duas médias são iguais, as hipóteses podem ser:\n\nH₀: média₁ = média₂ (não há diferença entre os grupos)\nH₁:\n\n-   média₁ ≠ média₂ (diferença bilateral)\n\n-   média₁ \\&lt; média₂ (diferença unilateral)\n\n-   média₁ \\&gt; média₂ (diferença unilateral)\nEssas formulações variam conforme a pergunta de pesquisa e o objetivo do estudo. O teste de hipóteses nos ajuda a tomar decisões com base em dados amostrais, reduzindo a incerteza ao analisar características populacionais.\n\n\nP-valor\nO p-valor representa a probabilidade de obter um resultado igual ou mais extremo do que o observado nos dados, assumindo que a hipótese nula seja verdadeira. Em termos simples, ele mede o quanto os dados observados são compatíveis com a hipótese nula.\nQuanto menor for o p-valor, maior a evidência contra a hipótese nula — indicando que o resultado encontrado dificilmente teria ocorrido ao acaso. Por outro lado, valores altos de p sugerem que os dados são consistentes com a hipótese nula e que qualquer diferença observada pode ser atribuída à variabilidade natural da amostra.\nNa prática, o p-valor é comparado a um nível de significância previamente definido (como 0,05 ou 0,01):\n\nSe o p-valor for menor que o nível de significância, rejeita-se a hipótese nula, indicando evidência estatística de que há uma diferença entre os grupos ou condições estudadas.\nSe o p-valor for maior, não há evidência suficiente para rejeitar a hipótese nula, e considera-se que não há diferença estatisticamente significativa.\n\nO p-valor, portanto, é uma ferramenta fundamental na tomada de decisões em testes estatísticos, ajudando a interpretar os resultados com base na probabilidade.\n\n\nAgora vamos praticar:\n\n\nVisualização e exportação de dados\nUtilizando o conjunto de dados magnésio, foi criado um gráfico do tipo boxplot para representar a distribuição dos valores. Para complementar a visualização, utilizamos a função annotate() do ggplot2, que permite inserir anotações personalizadas diretamente no gráfico, facilitando a interpretação de pontos importantes ou destacando informações específicas.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\n\nmg &lt;- read_excel(\"dados-diversos.xlsx\")\nnames(mg)\n\n\n[1] \"tratamento\" \"tempo\"      \"severidade\"\n\n\nCode\nmg |&gt;\n  ggplot(aes(tratamento, severidade))+\n  geom_jitter(width = 0.05)+\n  geom_boxplot(fill = NA,\n               outlier.colour = NA)+\n  ylim(5, 20)+\n  annotate(geom = \"text\",\n           x = 0.7, y = 19,\n           label = \"t = 8.15; p &lt; 0.001\")\n\n\n\n\n\n\n\nTeste T\n\n\nCode\nmg2 &lt;- mg |&gt;\n  pivot_wider(id_cols = 1,\n              names_from = tratamento,\n              values_from = severidade)\n\n\nPara aplicar o teste t, criamos um novo objeto chamado mg2, copiando os dados do objeto mg. Em seguida, utilizamos a função pivot_wider() para reorganizar o formato da base de dados. Essa função é utilizada para transformar dados no formato “longo” em formato “largo”, ou seja, ela aumenta o número de colunas e reduz o número de linhas.\nNo uso de pivot_wider(), dois argumentos principais são essenciais:\n\nnames_from: indica a coluna cujos valores serão transformados em nomes de novas colunas;\nvalues_from: indica a coluna cujos valores preencherão as células dessas novas colunas.\n\nEssa transformação facilita a aplicação de testes estatísticos como o teste t, que muitas vezes requerem os dados organizados em colunas separadas para cada grupo comparado.\n\n\nCode\nt &lt;- t.test(mg2$tempo, mg2$severidade )\n#install.packages(\"report\")\nlibrary(report)\nreport(t)\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe One Sample t-test testing the difference between mg2$tempo (mean = 31.50)\nand mu = 0 suggests that the effect is positive, statistically significant, and\nlarge (difference = 31.50, 95% CI [16.34, 46.66], t(9) = 4.70, p = 0.001;\nCohen's d = 1.49, 95% CI [0.55, 2.39])\n\n\nAgora visualizaremos os nossos resultados:\n\n\nCode\nmg |&gt;\n  ggplot(aes(tratamento, severidade))+\n  stat_summary(fun.data = \"mean_se\")"
  },
  {
    "objectID": "hipotese.html#pacote-infer",
    "href": "hipotese.html#pacote-infer",
    "title": "",
    "section": "Pacote infer",
    "text": "Pacote infer\nO pacote infer oferece uma abordagem moderna e elegante para realizar inferência estatística, utilizando uma sintaxe coerente com o estilo do tidyverse. Ele simplifica o processo de análise ao estruturar a inferência em quatro etapas principais, cada uma representada por uma função intuitiva:\n\nspecify(): define a variável ou a relação entre variáveis que será foco da análise.\nhypothesize(): formula a hipótese nula que será testada.\ngenerate(): simula conjuntos de dados que seguem a hipótese nula, possibilitando a construção da distribuição nula.\ncalculate(): computa as estatísticas de interesse sobre os dados simulados, permitindo a avaliação da evidência contra a hipótese nula.\n\nEssa estrutura modular torna a inferência estatística mais transparente, reprodutível e integrada ao ecossistema tidyverse, facilitando o entendimento e a comunicação dos resultados.\n\n\nCode\n#install.packages(\"dplyr\")\nlibrary(dplyr)\nlibrary(infer)\n\n# Verifique o nome das colunas\nnames(mg)\n\n\n[1] \"tratamento\" \"tempo\"      \"severidade\"\n\n\nCode\n#comparação entre os tratamentos Gotejamento e Aspersor, porque teste T faz para 2 niveis.\nmg_filtrado &lt;- mg |&gt;\n  filter(tratamento %in% c(\"Gotejamento\", \"Aspersor\"))\n\nmg_filtrado |&gt;\n  t_test(severidade ~ tratamento, order = c(\"Gotejamento\", \"Aspersor\"))\n\n\n# A tibble: 1 × 7\n  statistic  t_df p_value alternative estimate lower_ci upper_ci\n      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1      2.99  10.6  0.0128 two.sided       15.5     4.02     26.9"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Início",
    "section": "",
    "text": "Graduanda em Agronomia pela Universidade Federal de Campina Grande.\nEste site foi criado como parte do projeto da disciplina Análise e Visualização de dados em Fitopatologia (FIP606).\nContato: maria.a.leite@ufv.br\nUniversidade Federal de Viçosa – MG"
  },
  {
    "objectID": "index.html#maria-izabel",
    "href": "index.html#maria-izabel",
    "title": "Início",
    "section": "",
    "text": "Graduanda em Agronomia pela Universidade Federal de Campina Grande.\nEste site foi criado como parte do projeto da disciplina Análise e Visualização de dados em Fitopatologia (FIP606).\nContato: maria.a.leite@ufv.br\nUniversidade Federal de Viçosa – MG"
  },
  {
    "objectID": "introducao.html",
    "href": "introducao.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "introducao.html#sofware-r---análise-de-dados",
    "href": "introducao.html#sofware-r---análise-de-dados",
    "title": "",
    "section": "Sofware R - Análise de Dados",
    "text": "Sofware R - Análise de Dados\nA análise de dados tem se tornado cada vez mais essencial em diversas áreas do conhecimento, sendo uma ferramenta estratégica para tomada de decisões, identificação de padrões e geração de conhecimento a partir de informações brutas. Nesse contexto, o R se destaca como uma linguagem de programação poderosa e amplamente utilizada para análise estatística, visualização de dados e ciência de dados em geral. Gratuito e de código aberto, o R oferece uma ampla gama de pacotes e recursos que facilitam desde análises básicas até modelagens complexas.\nAo iniciar sua jornada no universo da análise de dados com o RStudio, é fundamental saber por onde começar. Há uma variedade de materiais valiosos disponíveis, sendo essencial saber como acessá-los e aproveitá-los de forma estratégica. Uma obra recomendada para iniciantes é o livro Introdução à Ciência de Dados no R, que fornece uma base sólida para compreender os principais conceitos da área e aplicar técnicas de análise de dados de maneira eficiente.\nÉ importante destacar que os materiais disponibilizados neste site foram elaborados com o objetivo de apoiar o aprendizado. No entanto, devido à complexidade dos temas abordados, nem todos os conteúdos contam com anotações detalhadas. Por isso, esses recursos devem ser utilizados como material complementar, e não como fonte principal de estudo.\nCom isso em mente, damos início à nossa jornada no R, explorando seus objetos e funções mais básicas — etapa fundamental para quem deseja desenvolver habilidades sólidas em análise de dados."
  },
  {
    "objectID": "introducao.html#download-r-studio",
    "href": "introducao.html#download-r-studio",
    "title": "",
    "section": "Download R Studio",
    "text": "Download R Studio\nLink para instalação do R e do R Studio (https://posit.co/download/rstudio-desktop/)"
  },
  {
    "objectID": "introducao.html#objetos-e-funções",
    "href": "introducao.html#objetos-e-funções",
    "title": "",
    "section": "Objetos e funções",
    "text": "Objetos e funções\n\nObjetos no R\nEm R, objetos são estruturas que armazenam informações, podendo ser números, textos, funções ou até conjuntos de dados. Para criar um objeto, utiliza-se o operador de atribuição &lt;-. Por exemplo:\n\n\nCode\na &lt;- 1\n\n\nNeste exemplo, o número 1 foi atribuído ao objeto chamado a. As bases de dados em R geralmente são armazenadas como data frames, que são objetos que organizam dados em forma de tabela (colunas e linhas).\n\n\nCode\n#O R e uma linguagem orientada a objetos\n\nx&lt;-10\nx\n\n\n[1] 10\n\n\nCode\nx &lt;- sqrt(2)       # armazena a raiz quadrada de 2 em x\nx\n\n\n[1] 1.414214\n\n\nCode\ny&lt;-sqrt(5); y\n\n\n[1] 2.236068\n\n\nCode\ny+x\n\n\n[1] 3.650282\n\n\nCode\n#---------------------------------------------------------------------\n# Operacoes aritmeticas\n\n# Voce pode usar o R para avaliar algumas expressoes aritmeticas simples. Por exemplo:\n 1+2+3           # somando estes numeros ...\n\n\n[1] 6\n\n\nCode\n#[1] 6           # obtem-se a resposta marcada com [1]\n\n 2+3*4           # um pouquinho mais complexo\n\n\n[1] 14\n\n\nCode\n#[1] 14          # prioridade de operacoes (multiplicacao primeiro)\n\n (3/2)+1\n\n\n[1] 2.5\n\n\nCode\n#[1] 2.5         # assim como divisao\n\n  4*3^3          # potencias sao indicadas por  ** ou ^\n\n\n[1] 108\n\n\nCode\n#[1] 108         # e tem prioridade sobre multiplicaca e divisao\n\n\n#------------------------------------------------------------------------------\n# O R tambem disponibiliza funcoes como as que voce encontra em uma calculadora\n\nsqrt(2)  # Raiz quadrada\n\n\n[1] 1.414214\n\n\nCode\n#[1] 1.414214\n\n27^(1/3) # Raiz cubica\n\n\n[1] 3\n\n\nCode\n64^(1/4) # Raiz quarta\n\n\n[1] 2.828427\n\n\nCode\nsin(3.14159)         # seno(Pi radianos)  \n\n\n[1] 2.65359e-06\n\n\nCode\n#[1] 2.65359e-06     # e a resposta e bem proxima de zero\n\n#O valor Pi esta disponivel como uma constante no R. Tente isto:\n sin(pi)\n\n\n[1] 1.224606e-16\n\n\nCode\n#[1] 1.224606e-16     bem mais proximo de zero ...\n\n\n# Lista resumida de algumas funcoes aritmeticas no R: \n\n#sqrt=  raiz quadrada\n#abs=   valor absoluto (positivo)\n#sin, cos, tan =        funcoes trigonometricas\n#asin, acos, atan = funcoes trigonometricas inversas\n#sinh, cosh, tanh = funcoes hiperbolicas\n#asinh, acosh, atanh =  funcoes hiperbolicas inversas\n#exp, log = exponencial e logaritmo natural\n\n#log e o logaritmo natural (ln)\nlog(5)    # log natural ou neperiano de 5\n\n\n[1] 1.609438\n\n\nCode\nlog10(5)  # log de 5 na base 10\n\n\n[1] 0.69897\n\n\nCode\nlog2(5)   # log de 5 na base 2\n\n\n[1] 2.321928\n\n\nCode\nexp(1.61) # exponencial ou funcao inversa de log(5)\n\n\n[1] 5.002811\n\n\nCode\n#----------------------------------------------------------------------------------\n#Vetores\nx1&lt;-10\nx1\n\n\n[1] 10\n\n\nCode\nx2 &lt;- c(1, 3, 6)\nx2\n\n\n[1] 1 3 6\n\n\nCode\nx2[1]\n\n\n[1] 1\n\n\nCode\nx2[2]\n\n\n[1] 3\n\n\nCode\nlength(x2)     #tamanho do vetor\n\n\n[1] 3\n\n\nCode\nis.vector(x2)\n\n\n[1] TRUE\n\n\nCode\nis.matrix(x2)\n\n\n[1] FALSE\n\n\nCode\nis.numeric(x2)\n\n\n[1] TRUE\n\n\nCode\nis.character(x2)\n\n\n[1] FALSE\n\n\nCode\nx3 &lt;- 1:10\nx3\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nCode\nx4 &lt;- seq(0,1, by=0.1)\nx4\n\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nCode\nx4[x4 &gt; 0.5]\n\n\n[1] 0.6 0.7 0.8 0.9 1.0\n\n\nCode\nx4[x4 &gt;= 0.5]\n\n\n[1] 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nCode\nx4 &lt;= 0.5\n\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n\n\nCode\nx5 &lt;- seq(0,1,  len=12)\nx5\n\n\n [1] 0.00000000 0.09090909 0.18181818 0.27272727 0.36363636 0.45454545\n [7] 0.54545455 0.63636364 0.72727273 0.81818182 0.90909091 1.00000000\n\n\nCode\nx6 &lt;- rep(1, 5)\nx6\n\n\n[1] 1 1 1 1 1\n\n\nCode\nx7 &lt;- rep(c(1, 2), c(3, 5))# repete 1 tres vezes e 2 cinco vezes\nx7\n\n\n[1] 1 1 1 2 2 2 2 2\n\n\nCode\nx8 &lt;- rep(1:3, rep(5))\nx8\n\n\n [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3\n\n\nCode\nx9 &lt;- rep(1:3, rep(5,3))\nx9\n\n\n [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3\n\n\nCode\nset.seed(321)\nx10 &lt;- rnorm(10, mean=70, sd=10)\nx10\n\n\n [1] 87.04903 62.87961 67.22015 68.80351 68.76039 72.68184 77.26841 72.33135\n [9] 73.39114 64.48085\n\n\nCode\nsum(x10) # soma\n\n\n[1] 714.8663\n\n\nCode\nmean(x10)# media\n\n\n[1] 71.48663\n\n\nCode\nvar(x10) # variancia\n\n\n[1] 48.59807\n\n\nCode\nsd(x10)  # desvio padrao\n\n\n[1] 6.971231\n\n\nCode\nmin(x10) # minimo\n\n\n[1] 62.87961\n\n\nCode\nmax(x10) # maximo\n\n\n[1] 87.04903\n\n\nCode\nsummary(x10) # resumo\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  62.88   67.61   70.57   71.49   73.21   87.05 \n\n\nCode\nsummary(1:10)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    3.25    5.50    5.50    7.75   10.00 \n\n\nCode\n#-----------------------------------------------------------------------------\n\n\nData Frame\nUm data frame no R é uma estrutura de dados bidimensional que armazena informações em forma de tabela, com linhas e colunas. Cada coluna pode conter diferentes tipos de dados (números, textos, fatores etc.), mas todas as colunas devem ter o mesmo número de linhas. É amplamente usado para manipulação e análise de dados estatísticos.\n\n\nCode\n# Criação do data frame\n#Cria um data frame chamado d1 com: Coluna X: números de 1 a 10. Coluna Y: valores fornecidos manualmente.\n#d1- Mostra a tabela completa com as colunas X e Y.\n#names(d1)- Mostra os nomes das colunas do data frame: \"X\" e \"Y\".\n# d1$X e d1$Y - Acessa separadamente os valores das colunas X e Y\n#plot(d1, pch=17, col=\"blue\") -Cria um gráfico de dispersão dos dados (Y em função de X).\n\n#pch=17 define o símbolo dos pontos como triângulo.col=\"blue\" define a cor azul para os pontos.\n# A seguir: \n\nd1 &lt;- data.frame(X = 1:10, Y = c(51, 54, 61, 67, 68, 75, 77, 75, 80, 82))\nd1\n\n\n    X  Y\n1   1 51\n2   2 54\n3   3 61\n4   4 67\n5   5 68\n6   6 75\n7   7 77\n8   8 75\n9   9 80\n10 10 82\n\n\nCode\nnames(d1)\n\n\n[1] \"X\" \"Y\"\n\n\nCode\nd1$X\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nCode\nd1$Y\n\n\n [1] 51 54 61 67 68 75 77 75 80 82\n\n\nCode\nplot(d1, pch=17,col=\"blue\")\n\n\n\n\n\nCode\nplot(d1$X, d1$Y)\n\n\n\n\n\n\n\nFunções e Argumentos\nFunções são blocos de código que realizam tarefas específicas. Ao chamar uma função, os valores passados entre parênteses são chamados de argumentos. Uma função pode receber um ou vários argumentos, separados por vírgulas. Por exemplo:\n\n\nCode\nsum(1, 2)\n\n\n[1] 3\n\n\nNeste caso, a função sum() soma os valores 1 e 2, retornando o resultado 3.\n\n\nClasses\nR trabalha com diferentes classes de dados, que determinam o tipo de informação armazenada. Os principais tipos são:\n\nnumeric: números (ex.: 3.14, -10, 7)\ncharacter: textos entre aspas (ex.: “banana”, “R é ótimo”)\nlogical: valores lógicos, como TRUE ou FALSE\n\nTextos são geralmente utilizados em variáveis categóricas, e sempre devem ser inseridos entre aspas para diferenciá-los de nomes de objetos ou funções.\n\n\nVetores\nUm vetor é uma estrutura que armazena vários valores do mesmo tipo. Para criar um vetor, usamos a função c() com os valores separados por vírgulas:\n\n\nCode\nvetor1 &lt;- c(1, 5, 3, -10)\n\n\n\n\nOperações Lógicas\nOperações lógicas verificam condições e retornam valores booleanos: TRUE (verdadeiro) ou FALSE (falso). Por exemplo:\nPrincipais operadores lógicos:\n\nx &lt; y  (x é menor que y?)\nx &lt;= y (x é menor ou igual a y?)\nx &gt; y  (x é maior que y?)\nx &gt;= y (x é maior ou igual a y?)\nx == y (x é igual a y?)\nx != y (x é diferente de y?)\n!x   (negação de x)\nx | y (x ou y são verdadeiros?)\nx & y (x e y são verdadeiros?)\nx %in% y (x pertence ao vetor y?)\nxor(x, y) (exclusão lógica: apenas um dos dois é verdadeiro)\n\n\n\nValores Especiais\nNA: representa dados faltantes ou desconhecidos. Indica que o valor existe, mas não foi informado.\nOutros valores especiais incluem NaN (resultado indefinido), Inf (infinito positivo) e -Inf (infinito negativo).\n\n\nOperador Pipe\nO pipe (%&gt;% do pacote {magrittr} ou |&gt; nativo do R) permite encadear comandos de forma mais clara, passando o resultado de uma operação como entrada da próxima. Isso facilita a leitura e a organização do código. Por exemplo:\ndados %&gt;% filter(categoria == “A”) %&gt;% summarise(media = mean(valor))\nCada etapa ocorre de forma sequencial e legível.\n\n\nOperador Cifrão ($)\nO operador $ é utilizado para acessar colunas específicas de um data frame pelo nome. A sintaxe é:\n{dados$variavel}\nPor exemplo, para acessar a coluna dados de um data frame chamado dad\n{dad$dados}\n\n\nComentários\nNo R, o símbolo # é usado para adicionar comentários no código. Tudo que estiver após o # em uma linha é ignorado pelo interpretador e serve apenas como anotação para quem está lendo o script. Comentários são úteis para explicar o que o código faz, registrar observações ou organizar o raciocínio durante a programação. Eles não afetam a execução nem o desempenho do script. É uma boa prática usar comentários para facilitar a manutenção e o entendimento do código, especialmente em projetos maiores ou colaborativos."
  },
  {
    "objectID": "regressao.html",
    "href": "regressao.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "regressao.html#ec50",
    "href": "regressao.html#ec50",
    "title": "",
    "section": "EC50",
    "text": "EC50\n\nPacote drc e modelos de regressão dose-resposta\nO pacote drc é amplamente utilizado para ajustar modelos de regressão dose-resposta, especialmente em estudos biológicos e toxicológicos. Ele oferece uma variedade de funções para modelar curvas de resposta a diferentes níveis de dose, fornecendo suporte para modelos como log-logístico, log-probit, Weibull, entre outros. Um dos principais recursos do pacote é a estimativa de valores como a EC50 — a dose necessária para provocar 50% do efeito máximo.\n\n\nModelo log-logístico de 3 parâmetros (LL.3)\nO modelo log-logístico de três parâmetros (LL.3) é adequado quando se observa uma relação em forma de curva sigmoide (ou S) entre a dose aplicada e a resposta observada. Ele assume que a resposta aumenta (ou diminui) de forma gradual com o aumento da dose, até atingir um platô. Esse modelo estima três parâmetros:\n\nb: a inclinação da curva (slope),\nd: o valor máximo da resposta (plateau superior),\ne: a dose que produz 50% da resposta máxima (EC50).\n\nEsse tipo de modelo é ideal para casos em que não há resposta basal clara (ou seja, onde o valor mínimo da resposta é fixado em zero).\nO comando abaixo ajusta um modelo de regressão não linear utilizando a função drm() do pacote drc, voltada para análise de curvas dose-resposta.\n\nGC_mean ~ Dose: define que GC_mean é a variável resposta e Dose é a variável preditora.\ndata = FGT152: indica que os dados utilizados estão no dataframe FGT152.\n\nfct = LL.3(): especifica o uso do modelo log-logístico de 3 parâmetros (LL.3), comumente usado para curvas com padrão sigmoide.\nApós o ajuste, pode-se avaliar a qualidade do modelo por meio do AIC:\n\n\nCode\nlibrary(drc)\n\ndrc1 &lt;- drm(GC_mean ~ Dose, data = FGT152,\n            fct = LL.3())\nAIC(drc1)\n\n\n[1] 33.60846\n\n\n\n\nCode\nsummary(drc1)\n\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value     p-value    \nb:(Intercept)  0.401905   0.053427  7.5225    0.001672 ** \nd:(Intercept) 47.540342   1.459890 32.5643 0.000005302 ***\ne:(Intercept)  7.220130   2.340119  3.0854    0.036739 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.993805 (4 degrees of freedom)\n\n\n\n\nCode\nplot(drc1)\n\n\n\n\n\n\n\nCode\nED(drc1, 50)\n\n\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50   7.2201     2.3401\n\n\nEssa função calcula a dose correspondente ao nível de efeito desejado (neste caso, 50%).\n\n\nModelo W1.3 (Weibull de 3 parâmetros)\nO modelo W1.3 é uma alternativa ao log-logístico, oferecendo maior flexibilidade devido à inclusão de um parâmetro de assimetria (g). Esse parâmetro permite que a curva dose-resposta seja assimétrica, ajustando-se melhor a dados que não seguem o padrão sigmoide simétrico. O W1.3 é particularmente útil quando a resposta apresenta uma taxa de crescimento acelerada ou desacelerada, e seu desempenho pode ser comparado com outros modelos por meio do AIC — sendo preferido quando apresenta menor valor.\n\n\nCode\ndrc1 &lt;- drm(GC_mean ~ Dose, data = FGT152,\n            fct = W1.3())\nAIC(drc1)\n\n\n[1] 37.75192\n\n\n\n\nCode\nsummary(drc1)\n\n\n\nModel fitted: Weibull (type 1) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n              Estimate Std. Error t-value    p-value    \nb:(Intercept)  0.28354    0.04760  5.9567   0.003987 ** \nd:(Intercept) 48.38112    2.09996 23.0390 0.00002103 ***\ne:(Intercept) 30.12379   12.58003  2.3946   0.074796 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.680509 (4 degrees of freedom)\n\n\n\n\nCode\nplot(drc1)\n\n\n\n\n\n\n\nCode\nED(drc1, 50)\n\n\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50   8.2704     3.6719\n\n\n\n\nPacote ec50estimator\nO pacote ec50estimator foi desenvolvido para facilitar a estimativa da EC50 (concentração efetiva para 50% de resposta) de forma prática e direta. Ele é especialmente útil quando se deseja comparar os valores de EC50 entre diferentes grupos ou identificadores (ID), como isolados, tratamentos ou populações. Essa comparação permite identificar possíveis variações na sensibilidade ou resposta à dose entre os grupos analisados.\nAlém de estimar a EC50, o pacote também pode fornecer intervalos de confiança e realizar ajustes automáticos de modelos, tornando-se uma ferramenta eficiente para estudos que envolvem curvas dose-resposta.\n\n\nCode\nlibrary(ec50estimator)\n\ndf_ec50 &lt;- estimate_EC50(GC_mean ~ Dose,\n                         data = dat2,\n                         isolate_col = \"Code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\n\ndf_ec50 |&gt;\n  ggplot(aes(Estimate, reorder(ID, Estimate)))+\n  geom_point()+\n  geom_errorbar(aes(xmin = Lower,\n                    xmax = Upper), width = 0.1)+\n  xlim(0,30)"
  },
  {
    "objectID": "testt.html",
    "href": "testt.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "testt.html#análises-estatísticas",
    "href": "testt.html#análises-estatísticas",
    "title": "",
    "section": "ANÁLISES ESTATÍSTICAS",
    "text": "ANÁLISES ESTATÍSTICAS\nAqui veremos como determinar oo tipo de analise de acordo com o numero e tipo de variavel independente (niveis do Fator, numero de tratamentos ou grupos que serão observados e comparados.\nNós veremos o Test T, Teste T paramétrico e Teste para dados não paramétricos. Vamos lá?"
  },
  {
    "objectID": "testt.html#teste-t",
    "href": "testt.html#teste-t",
    "title": "",
    "section": "Teste T",
    "text": "Teste T\nO teste t é uma ferramenta estatística usada para comparar duas médias provenientes de dois tratamentos ou grupos distintos, com o objetivo de avaliar se a diferença entre elas é estatisticamente significativa. Assim como outros testes estatísticos, o teste t fornece um valor de p, que representa a probabilidade de a diferença observada entre as médias ter ocorrido ao acaso.\nExistem dois tipos principais de teste t:\n\nTeste t para amostras dependentes (pareadas): utilizado quando as duas médias comparadas vêm da mesma população, mas em momentos diferentes (por exemplo, antes e depois de um tratamento).\nTeste t para amostras independentes (não pareadas): indicado quando se comparam duas populações distintas, sem relação entre si.\n\nExemplo prático: comparação entre dois tratamentos independentes\nPara esse xemplo usaremos um conjunto de dados, no qual, um pesquisador realizou um experimento para avaliar o impacto do magnésio (Mg), adicionado à solução nutritiva do solo, no controle de uma doença fúngica em plantas de arroz. O experimento seguiu um delineamento inteiramente casualizado, com 10 repetições, sendo cada repetição representada por um vaso com uma planta.\nDois tratamentos foram aplicados:\n\nControle (testemunha): sem adição de magnésio.\nTratamento com Mg: suplementado com magnésio na concentração de 2 mM.\n\nPara cada vaso, foi registrada a média do comprimento das lesões em um determinado tempo após a inoculação do patógeno. O objetivo é verificar se há diferença significativa entre os dois grupos.\n\nEtapas iniciais: preparação para a análise\nAntes da análise estatística, é necessário:\n\nCarregar os pacotes estatísticos apropriados.\nImportar o conjunto de dados com os resultados do experimento.\n\n\n\nCode\nlibrary(magrittr) \nlibrary(ggplot2) \nlibrary(dplyr)\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(gsheet)\n\n\ndados &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n\n\nhead(dados)\n\n\n# A tibble: 6 × 3\n  trat    rep  comp\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Mg2       1   9  \n2 Mg2       2  12.5\n3 Mg2       3  10  \n4 Mg2       4   8  \n5 Mg2       5  13.2\n6 Mg2       6  11  \n\n\nVamos iniciar a exploração dos dados realizando análises estatísticas descritivas, que nos permitem entender melhor as características gerais do conjunto de dados. Neste contexto, iremos calcular medidas de tendência central e de dispersão, como:\n\nMédia (mean): representa o valor médio dos dados;\nVariância (var): indica o quanto os valores se afastam da média;\nDesvio padrão (sd): mede a dispersão dos dados em torno da média;\nErro padrão (se): estima a variabilidade da média em diferentes amostras;\nIntervalo de confiança (ci): utilizado aqui com finalidade visual, para indicar a margem de variação esperada da média.\n\nEssas métricas ajudam a resumir e visualizar os dados de forma clara e fundamentada, servindo como base para análises comparativas ou inferenciais.\n\n\nCode\ndata2 &lt;- dados %&gt;%\n  dplyr::group_by(trat) %&gt;%\n  summarise(\n    mean_com = mean(comp),\n    sd_comp = sd(comp),\n    var_comp = var(comp),\n    n = n(),\n    se_comp = sd_comp / sqrt(n - 1),\n    ci = se_comp * qt(0,025, df = 9))\ndata2\n\n\n# A tibble: 2 × 7\n  trat    mean_com sd_comp var_comp     n se_comp    ci\n  &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Mg2         10.5    1.54     2.39    10   0.515  -Inf\n2 control     15.7    1.27     1.61    10   0.424  -Inf\n\n\n\n\nVisualização dos dados\nUma das formas mais diretas de interpretar um conjunto de dados é por meio da visualização gráfica. Quando há mais de seis repetições por grupo, uma alternativa eficiente é utilizar boxplots acompanhados dos pontos individuais, o que permite observar a distribuição, tendência central e possíveis outliers.\nNo entanto, neste caso, optaremos por representar os resultados em um gráfico de barras verticais, utilizando a média de cada grupo e adicionando o erro padrão (SE) como barra de erro. Essa abordagem facilita a comparação entre os grupos e fornece uma ideia da variabilidade dos dados, mantendo a clareza visual.\n\n\nCode\ndata2 |&gt; \n  ggplot(aes(trat, mean_com)) +\n  geom_col(width = 0.5,\n           fill = \"green\") +\n  geom_errorbar(aes(\n    ymin = mean_com - se_comp,\n    ymax = mean_com + se_comp),\n    width = 0.1) +\n  ylim(0,20) +\nlabs(x = \"Trat\", y = \"Comp (mm)\")\n\n\n\n\n\n\n\nIntervalo de Confiança\nAgora, os dados são representados com a inclusão do intervalo de confiança (IC). No gráfico a seguir, as barras verticais indicam o intervalo de confiança de 95% em torno da média de cada grupo. Essa visualização oferece uma noção da precisão das estimativas e permite avaliar, de forma gráfica, a sobreposição ou distinção entre os grupos analisados.\n\n\nCode\ndata2 |&gt; \n  ggplot(aes(trat, mean_com)) +\n  geom_col(width = 0.5, fill = \"green\") +\n  geom_errorbar(aes(\n    ymin = mean_com - ci,\n    ymax = mean_com + ci),\n    width = 0.1) +\n  ylim(0,20) +\nlabs(x = \"Trat\", y = \"Comp (mm)\")\n\n\n\n\n\nO conjunto de dados está organizado no formato largo, onde a variável de interesse (resposta) está concentrada em uma única coluna. Para facilitar a análise comparativa entre os tratamentos, é comum transformar esses dados em um formato que separe as respostas em colunas distintas para cada tratamento. Uma forma eficiente de fazer isso é utilizando a função pivot_wider(), que reorganiza os dados criando uma coluna para cada grupo de tratamento.\nDessa forma, geramos um novo conjunto chamado data_mg2, que apresenta as respostas (como o tamanho da lesão) distribuídas em colunas separadas para cada tratamento. No entanto, para criar gráficos com o ggplot2, é necessário trabalhar com os dados no formato longo, ou seja, com uma coluna contendo as respostas e outra indicando o tratamento. Portanto, é possível visualizar diretamente as respostas usando o conjunto original, que já está estruturado no formato adequado para o ggplot2.\n\n\nCode\nnames(dados)# ver nomes nas colunas\n\n\n[1] \"trat\" \"rep\"  \"comp\"\n\n\nCode\nlibrary(tidyr)\ndata_mg2 &lt;- dados |&gt;\n  pivot_wider(\n    id_cols = 1,          \n    names_from = trat,\n    values_from = comp,\n  )\ndata_mg2\n\n\n# A tibble: 10 × 3\n     rep   Mg2 control\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1   9      13.7\n 2     2  12.5    15.9\n 3     3  10      15.7\n 4     4   8      14.2\n 5     5  13.2    15.9\n 6     6  11      16.5\n 7     7  10.8    18  \n 8     8   9.5    14.4\n 9     9  10.8    16.4\n10    10  10.4    16  \n\n\n\nTeste de hipótese - teste t\nO teste t é uma análise estatística do tipo paramétrica, o que significa que sua aplicação depende do cumprimento de duas premissas fundamentais: a normalidade dos dados e a homogeneidade das variâncias entre os grupos (também chamada de homocedasticidade).\nSe os dados não atenderem à distribuição normal, é possível aplicar transformações apropriadas (como logaritmo, raiz quadrada, entre outras) para aproximá-los da normalidade, tornando o uso do teste t estatisticamente válido.\n\n\nCode\nt.test(data_mg2$Mg2, data_mg2$control, \npaired = F)\n\n\n\n    Welch Two Sample t-test\n\ndata:  data_mg2$Mg2 and data_mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\nA ordem correta para a aplicação do teste t envolve a verificação prévia de suas premissas. O procedimento recomendado é o seguinte:\n\nTeste de normalidade: utilize a função shapiro.test() para avaliar se os dados seguem uma distribuição normal;\nTeste de homogeneidade das variâncias: aplique var.test() para verificar se os grupos possuem variâncias semelhantes (homocedasticidade);\n\nAplicação do teste t: se ambas as premissas forem atendidas (p &gt; 0,05 nos testes anteriores), então o t.test() pode ser utilizado com segurança.\nCaso o teste de variância indique heterocedasticidade (p &lt; 0,05), ainda é possível realizar o teste t, mas com o argumento var.equal = FALSE, o que ajusta o teste para variâncias diferentes.\nAlém disso, quando os dados são pareados (por exemplo, medidas antes e depois em um mesmo indivíduo), deve-se incluir o argumento paired = TRUE na função t.test().\n\n\n\nHomocedasticidade\nA homocedasticidade — ou homogeneidade das variâncias — é uma premissa essencial para a aplicação do teste t. Para verificar essa condição no caso de dois grupos, utiliza-se o teste F, que compara as variâncias dos grupos.\nNo R, essa análise pode ser realizada por meio da função var.test(), que deve ser aplicada a dois vetores numéricos representando os grupos a serem comparados. Para isso, os dados devem estar organizados em formato largo, de modo que cada grupo esteja em uma coluna separada.\nApós executar o teste, observe o valor de p na saída da função. Um p-valor maior que 0,05 indica que não há diferença significativa entre as variâncias (homocedasticidade), permitindo o uso do teste t com o argumento var.equal = TRUE. Caso contrário, considera-se que há heterocedasticidade, e deve-se utilizar var.equal = FALSE.\n\n\nCode\nattach(data_mg2)\nvar.test(Mg2, control)\n\n\n\n    F test to compare two variances\n\ndata:  Mg2 and control\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111 \n\n\n\n\nVerificação da Homocedasticidade\nAlém do teste estatístico de variância, a homocedasticidade também pode ser avaliada de forma gráfica. Uma abordagem comum é a utilização de um boxplot dos resíduos em relação aos tratamentos. Quando as variâncias são homogêneas, espera-se que os boxplots tenham tamanhos e amplitudes semelhantes entre os grupos, indicando distribuição equilibrada dos resíduos.\n\n\nAvaliação da Normalidade\nA normalidade dos dados é outro pressuposto fundamental para testes paramétricos. Ela pode ser verificada tanto por métodos gráficos — como histogramas, Q-Q plots e densidade — quanto por testes estatísticos específicos. Um dos mais utilizados é o teste de Shapiro-Wilk, acessado no R pela função shapiro.test(), que avalia se os dados seguem uma distribuição normal.\n\n\nCode\nshapiro.test(Mg2)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  Mg2\nW = 0.97269, p-value = 0.9146\n\n\n\n\nCode\nshapiro.test(control)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  control\nW = 0.93886, p-value = 0.5404\n\n\n\n\nAnálise Visual da Normalidade\nA verificação visual da normalidade pode ser feita por meio do QQ-Plot (Quantile-Quantile Plot), uma ferramenta gráfica que compara os quantis observados da amostra com os quantis esperados de uma distribuição normal. Se os pontos do gráfico se alinharem aproximadamente sobre a linha de referência, é um indicativo de que os dados seguem uma distribuição gaussiana.\nNo R, esse tipo de gráfico pode ser facilmente construído com as funções qqnorm() (que gera o gráfico) e qqline() (que adiciona a linha teórica de referência). Recomenda-se aplicar essas funções individualmente para cada variável que se deseja avaliar.\n\n\nCode\nqqnorm (Mg2)\nqqline(Mg2)\n\n\n\n\n\n\n\nCode\nqqnorm(control)\nqqline(control)\n\n\n\n\n\n\n\nDois tratamentos dependentes\nFeito isso vamos partir para tratamentos dependentes.\n\n\nQuando as premissas de normalidade não são atendidas\nCaso os dados não atendam às premissas de normalidade, é necessário utilizar métodos alternativos que não dependem da suposição de distribuição normal. No caso de comparações entre dois grupos, existem duas abordagens principais:\n\nTestes não paramétricos, como o teste de Wilcoxon para amostras pareadas ou o teste de Mann-Whitney para amostras independentes;\nMétodos baseados em reamostragem, como o bootstrapping, que permitem inferências estatísticas sem depender da forma da distribuição dos dados\n\nPara isso vamos usar um conjunto no qual, foi realizado um experimento para avaliar o impacto do uso de uma escala na acurácia e precisão de avaliações visuais da severidade de uma doença, feitas por diferentes avaliadores. A hipótese em teste é que o uso da escala melhora a acurácia das estimativas em comparação com avaliações realizadas sem esse auxílio visual.\nVamos usar conjunto de dados de um experimento, no qual dez avaliadores foram selecionados aleatoriamente e realizaram duas avaliações, uma com o uso da escala e outra sem. Foram obtidas cinco variáveis relacionadas à concordância entre as estimativas e os valores reais da severidade. Como cada avaliador foi avaliado duas vezes ao longo do tempo, os dados são considerados pareados, caracterizando amostras dependentes.\n\n\nEtapas iniciais: preparação dos dados\nO primeiro passo da análise é realizar a importação dos dados e o preparo do conjunto para as análises subsequentes, assegurando que as variáveis estejam corretamente estruturadas para aplicar os testes apropriados.\n\n\nCode\nescala &lt;- read_excel(\"dados-diversos.xlsx\", \"escala\")\nhead(escala)\n\n\n# A tibble: 6 × 7\n  assessment rater acuracia precisao vies_geral vies_sistematico vies_constante\n  &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 Unaided    A        0.809    0.826      0.979            1.19         0.112  \n2 Unaided    B        0.722    0.728      0.991            0.922       -0.106  \n3 Unaided    C        0.4      0.715      0.783            1.16         0.730  \n4 Unaided    D        0.818    0.819      0.999            0.948       -0.00569\n5 Unaided    E        0.748    0.753      0.993            1.10         0.0719 \n6 Unaided    F        0.45     0.751      0.925            0.802        0.336  \n\n\n\n\nCode\nescala2 &lt;- escala |&gt; \n  select(assessment, rater, acuracia)\nescala3 &lt;- escala2|&gt;\n  pivot_wider(1,\n              names_from = assessment,\n              values_from = acuracia)\n\n\nAgora iremos checar as premissias, comecando pela homocedasticidade:\n\n\nCode\nattach(escala3)\nvar.test(Aided1, Unaided)\n\n\n\n    F test to compare two variances\n\ndata:  Aided1 and Unaided\nF = 0.047894, num df = 9, denom df = 9, p-value = 0.0001082\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.01189625 0.19282187\nsample estimates:\nratio of variances \n        0.04789423 \n\n\nNormalidade:\n\n\nCode\nshapiro.test(Aided1)$p.valu\n\n\n[1] 0.4260888\n\n\n\n\nCode\nshapiro.test(Unaided)$p.value\n\n\n[1] 0.006910227\n\n\nVamos plotar um grafico, para cada um e visualizarmos:\n\n\nCode\nqqnorm(Aided1)\nqqline(Aided1)\n\n\n\n\n\n\n\nCode\nqqnorm(Unaided)\nqqline(Unaided)\n\n\n\n\n\n\n\nTeste T paramétrico para amostras pareadas\n\n\nCode\nt_escala &lt;- t.test(escala3$Aided1, escala3$Unaided,\n  paired = TRUE,\n  var.equal = F\n)\n\nt_escala\n\n\n\n    Paired t-test\n\ndata:  escala3$Aided1 and escala3$Unaided\nt = 4.4266, df = 9, p-value = 0.001655\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1159591 0.3583453\nsample estimates:\nmean difference \n      0.2371522 \n\n\n\n\nTeste para Dados Não Paramétricos\nTestes não paramétricos são métodos estatísticos que não dependem de premissas sobre a distribuição dos dados, como a normalidade, e são especialmente úteis quando se trabalha com amostras pequenas ou quando não é possível verificar ou satisfazer as suposições dos testes paramétricos.\nPara comparar duas amostras pareadas ou dependentes quando a distribuição não é normal, utiliza-se o teste de Wilcoxon para amostras pareadas, implementado no R pela função wilcox.test(). Ele é considerado o equivalente não paramétrico ao teste t pareado, sendo usado para avaliar se há diferença significativa entre as medianas das duas condições analisadas.\nEsse teste é recomendado sempre que os dados violarem a normalidade ou não permitirem a verificação dessa premissa, oferecendo uma alternativa robusta e confiável para comparação de grupos.\n\n\nCode\nwilcox.test(escala3$Aided1, escala3$Unaided, paired = TRUE)\n\n\n\n    Wilcoxon signed rank exact test\n\ndata:  escala3$Aided1 and escala3$Unaided\nV = 55, p-value = 0.001953\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "transformacao.html",
    "href": "transformacao.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "transformacao.html#exploração-dos-dados",
    "href": "transformacao.html#exploração-dos-dados",
    "title": "",
    "section": "Exploração dos dados",
    "text": "Exploração dos dados\nPara essas analises vamos explorar um conjunto específico: o conjunto de dados “mofo”, que faz parte da planilha intitulada “dados-diversos”. Familiarizar-se com os dados nos ajuda a identificar padrões, possíveis distorções e a necessidade de ajustes estatísticos.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\n\nmofo &lt;- read_excel(\"dados-diversos.xlsx\", \"mofo\")\n\n\nOs dados podem ser explorados por meio de diferentes tipos de visualizações, como gráficos de dispersão, histogramas e boxplots. Neste primeiro momento, vamos visualizar os valores da variável inc (incidência) em função dos tratamentos e do estudo ao qual pertencem. Para isso, utilizaremos a função ggplot(), incluindo tratamento no mapeamento estético principal, e study dentro da função facet_wrap(). Essa função permite gerar um gráfico para cada categoria da variável especificada, facilitando a comparação entre estudos.\n\n\nCode\nmofo |&gt;\n  ggplot(aes(treat, inc))+\n  facet_wrap(~study)+\n  geom_point()\n\n\n\n\n\nTambém é possível utilizar a função geom_col() para representar os dados de uma maneira alternativa, por meio de colunas proporcionais aos valores das variáveis. Essa abordagem é útil quando se deseja comparar magnitudes de forma direta entre categorias.\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# 1. Calcular a média de incidência por tratamento dentro de cada estudo\nmofo_resumo &lt;- mofo |&gt;\n  group_by(study, treat) |&gt;\n  summarise(inc = mean(inc, na.rm = TRUE), .groups = \"drop\")\n\n# 2. Gráfico combinado: colunas com médias + pontos individuais\nggplot() +\n  # Camada das colunas com médias\n  geom_col(data = mofo_resumo,\n           aes(x = treat, y = inc),\n           fill = \"lightblue\", width = 0.6) +\n  \n  # Camada dos pontos individuais\n  geom_point(data = mofo,\n             aes(x = treat, y = inc),\n             color = \"black\",\n             position = position_jitter(width = 0.15, height = 0)) +\n  \n  facet_wrap(~study) +\n  theme_minimal() +\n  labs(title = \"Incidência por Tratamento em Cada Estudo\",\n       x = \"Tratamento\",\n       y = \"Incidência\")\n\n\n\n\n\nOu ainda fazer um gráfico com colunas:\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Agrupar os dados por estudo e tratamento, calculando a média de incidência\nmofo_resumo &lt;- mofo |&gt;\n  group_by(study, treat) |&gt;\n  summarise(inc = mean(inc, na.rm = TRUE), .groups = \"drop\")\n\n# Criar o gráfico com colunas e facet_wrap\nmofo_resumo |&gt;\n  ggplot(aes(x = treat, y = inc)) +\n  geom_col(fill = \"steelblue\") +\n  facet_wrap(~study) +\n  theme_minimal() +\n  labs(title = \"Média de Incidência por Tratamento em Cada Estudo\",\n       x = \"Tratamento\",\n       y = \"Incidência Média\")\n\n\n\n\n\nHistogramas: Vamos construir dois histogramas para explorar a distribuição dos dados. O primeiro mostrará a distribuição da variável incidência, enquanto o segundo apresentará a distribuição dos valores de escleródio. Esses gráficos nos permitirão observar o padrão de dispersão, a simetria (ou assimetria) e a concentração dos dados em diferentes faixas de valores.\n\n\nCode\ninc &lt;- mofo |&gt;\n  ggplot(aes(x = inc)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\", bins = 30) +\n  labs(title = \"Histograma de Incidência\")\n\n# Histograma da variável scl com escala de cor baseada na contagem\nmofo |&gt;\n  ggplot(aes(x = scl, fill = ..count..)) +\n  geom_histogram(color = \"black\", bins = 30) +\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +\n  labs(title = \"Histograma de Scleródio\", fill = \"Contagem\")\n\n\n\n\n\nBoxplot: Vamos construir um boxplot para visualizar a distribuição e a variação dos dados da variável scl, facilitando a identificação de medianas, dispersão e possíveis outliers.\n\n\nCode\nscl &lt;- mofo |&gt;\n  ggplot(aes(x = \"\", y = scl)) +  # eixo x vazio pois é só uma variável\n  geom_boxplot(fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Boxplot da variável Scleródio\",\n       y = \"Scleródio\",\n       x = \"\") +\n  theme_minimal()\n\n\nPatchwork: iremos juntar os dois gráficos.\n\n\nCode\nlibrary(patchwork)\ninc + scl\n\n\n\n\n\n\nMédia dos dados\nApós a visualização dos dados, podemos calcular a média para resumir seu valor central. Para isso, podemos usar diferentes abordagens no R, como acessar diretamente uma coluna com $, aplicar a função mean() ao conjunto de dados ou utilizar a função summary(), que fornece um resumo estatístico incluindo a média.\n\n\nCode\nmofo$scl\n\n\n [1] 2194 1663 1313 1177  753 1343 1519  516  643  400  643  921 1196 1331  756\n[16]  338  581  588  231  925  119  394  206  275  131  588 5013 3619 2325 2588\n[31] 3969 1556 3175 1763 2894  350  419  644 2850 6216 2888 2272 2868 2412 2372\n[46] 3424 1744 1456 1732 1080 1592 3268\n\n\n\n\nTransformação dos dados\nComo abordado anteriormente podemos transformar os dados de diversas formas, as mais comuns são a logaritmica e a raiz quadrada.\n\n\nCode\nmofo2 &lt;- mofo |&gt;\n  mutate (scl2 = log(scl))\n  mofo2\n\n\n# A tibble: 52 × 6\n   study treat   inc   scl   yld  scl2\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1     1    76  2194  2265  7.69\n 2     1     2    53  1663  2618  7.42\n 3     1     3    42  1313  2554  7.18\n 4     1     4    37  1177  2632  7.07\n 5     1     5    29   753  2820  6.62\n 6     1     6    42  1343  2799  7.20\n 7     1     7    55  1519  2503  7.33\n 8     1     8    40   516  2967  6.25\n 9     1     9    26   643  2965  6.47\n10     1    10    18   400  3088  5.99\n# ℹ 42 more rows\n\n\n\n\nA transformação logarítmica\nA transformação logarítmica é especialmente útil quando os dados apresentam distribuição assimétrica positiva ou quando a variabilidade cresce exponencialmente conforme os valores aumentam. Para aplicar o logaritmo dos números no R, utilizamos a função log().\nAlém disso, a função mutate() do pacote dplyr permite criar ou modificar variáveis no conjunto de dados, facilitando a aplicação dessas transformações. Com mutate(), adicionamos novas colunas que são funções de variáveis já existentes, tornando o processo de transformação simples e integrado ao fluxo de análise.\nPara visualizar os dados faremos um histograma:\n\n\nCode\nmofo2 |&gt;\n    ggplot(aes(scl2))+\n    geom_histogram(bins = 10, fill = \"green\", color = \"black\")\n\n\n\n\n\n\n\nTransformação por raiz quadrada\nTransformação por raiz quadrada: essa transformação é útil para reduzir a assimetria em dados com distribuição assimétrica positiva.\n\n\nCode\nmofo2 &lt;- mofo |&gt;\n  mutate (scl2 = sqrt(scl))\n  mofo2\n\n\n# A tibble: 52 × 6\n   study treat   inc   scl   yld  scl2\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1     1    76  2194  2265  46.8\n 2     1     2    53  1663  2618  40.8\n 3     1     3    42  1313  2554  36.2\n 4     1     4    37  1177  2632  34.3\n 5     1     5    29   753  2820  27.4\n 6     1     6    42  1343  2799  36.6\n 7     1     7    55  1519  2503  39.0\n 8     1     8    40   516  2967  22.7\n 9     1     9    26   643  2965  25.4\n10     1    10    18   400  3088  20  \n# ℹ 42 more rows\n\n\nNós utilizamos a função sqrt() dentro da função mutate(), que permite criar ou modificar variáveis no conjunto de dados.\nPara visualizar os dados faremos um histograma:\n\n\nCode\n mofo2 |&gt;\n    ggplot(aes(scl2))+\n    geom_histogram(bins = 10, fill = \"orange\", color = \"black\")\n\n\n\n\n\nTestes nos dados da variável produtividade.\n\n\nCode\nmofo2 |&gt;\n    ggplot(aes(yld))+\n    geom_histogram(bins = 10, fill = \"blue\", color = \"white\")\n\n\n\n\n\n\n\nFunção arrange()\nAgora vamos utilizar a função arrange() com o conjunto de dados survey. Essa função serve para ordenar as linhas do dataframe de acordo com uma ou mais colunas, podendo ser em ordem crescente (padrão) ou decrescente — para isso, basta usar o sinal de menos antes do nome da coluna.\n\n\nCode\nsurvey &lt;- read_excel(\"dados-diversos.xlsx\", \"survey\")\n\n\nsurvey |&gt;\n  filter(state == \"RS\") |&gt;\n  count(species, residue) |&gt;\n  arrange(n) |&gt;\n#slice(1) |&gt;\nrename(res = residue) |&gt;\nmutate(n_class = case_when(\n  n &lt; 30 ~ \"baixa\",\n       TRUE ~ \"Alta\"))\n\n\n# A tibble: 4 × 4\n  species res         n n_class\n  &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;  \n1 Fspp    corn       22 baixa  \n2 Fspp    soybean    26 baixa  \n3 Fgra    corn      147 Alta   \n4 Fgra    soybean   255 Alta   \n\n\nO primeiro argumento de arrange() é o conjunto de dados, seguido das colunas pelas quais você deseja ordenar.\nAlém disso, outras funções úteis para manipulação de dados são:\n\nslice(): seleciona linhas específicas pela sua posição no dataframe;\nfilter(): filtra as linhas com base em condições aplicadas aos valores das colunas;\ncount(): conta o número de ocorrências de cada valor único em uma variável, podendo usar pesos.\n\nEssas funções facilitam a organização, seleção e sumarização dos dados para análises mais eficientes."
  }
]